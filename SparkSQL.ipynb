{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uPdq9IyTCxAR",
        "ETL_qScRCxAV",
        "kCOZkWwwCxAl",
        "1BAkG_-aCxA0",
        "l_-aaH1QCxBE",
        "NX9CIV7uCxBH",
        "2ImgbGzOCxBt",
        "iHvbWot8CxCx",
        "1K0u_C5CCxEE",
        "HlHGY3PsCxEb",
        "LGVtXg97CxE0",
        "z6vKG3-ECxFP",
        "HtO0ttWFCxGA",
        "dANkRILMCxGe",
        "ZXu770mZCxHi",
        "ne6iUvniCxIa",
        "Q978vCagCxI2",
        "fOeHKEj0CxJX",
        "o9uOvjWoCxJ4",
        "TSH0B8THCxKA",
        "ly1RnCoTCxKU",
        "WDNIHIm9CxKs",
        "g67PGS0nCxK5",
        "TdIIiunLCxLT",
        "pIGySExFCxLt",
        "_oT_8GP5CxLv",
        "lHVuzYMaCxL4",
        "DgBV311iCxNB",
        "0xmsOK56CxNR",
        "PKDPVZMcCxN4",
        "rBjBm6P4CxOG",
        "2KgwdIczCxPu",
        "yBXADrjQCxPv",
        "5ph60368CxP9",
        "BqHvRwT2CxQR",
        "cvrBce7wCxQm",
        "49HlwnsJCxQ4",
        "iKnAry6SCxRA",
        "uMqn-uUdCxRV",
        "mkJ9AjNECxTB",
        "7DslhTPfCxTr",
        "u9oDUz9TCxUG",
        "HPji5VjiCxUg",
        "zpPKEFT3CxVb",
        "Bfs22keoCxWm",
        "PyuIbc60CxYM",
        "CdiSfp0hCxZ7",
        "PuEwHyFZCxa-",
        "G7gNW7vICxcl",
        "9mEtsb7DCxd5",
        "muI_i15TCxeK",
        "xyahwFAiCxee",
        "MJBE2Gv_Cxeo",
        "fwObksb8CxfA",
        "eU5Z5kS3CxfK",
        "ziBv8PHnCxfN",
        "jgm5zAXUCxfg",
        "mGm5q-4_Cxf3",
        "nNn414wKCxgP"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXrDvSOZCw8-"
      },
      "source": [
        "# Spark Operations using Spark DataFrames and Spark SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMWw7DrRMF8O"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkvO02qzMGPP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLNRdg12Cw9Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "37b12a05-0ee6-4277-9a4b-2364409672d0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97WnQXMVC8KC"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb-2cfe1C_1L"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0YFpWtUMFTF"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54vP-r67DCBp"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDbS2EaaCw9h"
      },
      "source": [
        "### 1.Create  SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy3l_pfLC6AU"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "      .builder \\\n",
        "      .appName('PySpark on Google Colab') \\\n",
        "      .master('local[*]') \\\n",
        "      .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaApy08QCw9z"
      },
      "source": [
        "### 2. Check the Spark Session Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WYIuoVD3Cw94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "ae7d7ada-fe7e-40e0-f0a5-300503bee3ca"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e208faca4eef:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark on Google Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fb77b8c60d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlQ-vYC4Cw-F"
      },
      "source": [
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q5azDR3Cw-X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "798ad0b5-ee9d-41ce-b0dd-3dfd195bdc56"
      },
      "source": [
        "sc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e208faca4eef:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark on Google Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=PySpark on Google Colab>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGgAhS7PCw-r"
      },
      "source": [
        "## ** Spark DataFrame **\n",
        "\n",
        "#### A DataFrame is the most common Structured API and simply represents a table of data with rows and columns. \n",
        "<br> The list that defines the columns and the types within those columns is called the schema. \n",
        "<br> One can think of a DataFrame as a spreadsheet with named columns.\n",
        "<br> A spreadsheet sits on one computer in one specific location, whereas a Spark DataFrame can span thousands of computers.\n",
        "<br> The reason for putting the data on more than one computer should be intuitive: \n",
        "<br>     either the data is too large to fit on one machine or \n",
        "<br>     it would simply take too long to perform that computation on one machine.\n",
        "\n",
        "#### NOTE\n",
        "Spark has several core abstractions: Datasets, DataFrames, SQL Tables, and Resilient Distributed Datasets (RDDs). \n",
        "<br> These different abstractions all represent distributed collections of data. \n",
        "<br> The easiest and most efficient are DataFrames, which are available in all languages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySgX0AfkCw-x"
      },
      "source": [
        "### 3. Create Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R36hBf6oCw-1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5642534f-fb6b-418e-ffc8-e53a4885e9e1"
      },
      "source": [
        "myDF = spark.createDataFrame([[1, 'Alice', 30],\n",
        "                              [2, 'Bob', 28],\n",
        "                              [3, 'Cathy', 31], \n",
        "                              [4, 'Dave', 56]], ['Id', 'Name', 'Age'])\n",
        "\n",
        "myDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+---+\n",
            "| Id| Name|Age|\n",
            "+---+-----+---+\n",
            "|  1|Alice| 30|\n",
            "|  2|  Bob| 28|\n",
            "|  3|Cathy| 31|\n",
            "|  4| Dave| 56|\n",
            "+---+-----+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6vKSJ34Cw_C"
      },
      "source": [
        "#### Create Dataframe from an RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "oN15L1dsCw_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6921ac8c-8b0a-452c-8227-9d0b74185d0a"
      },
      "source": [
        "# Reading from local file system.\n",
        "#trainRDD = sc.textFile(\"file:///home/thomasj/Batch78/SparkSQL/SalesData/train.csv\")\n",
        "\n",
        "# Read from hdfs file system.\n",
        "trainRDD = sc.textFile(\"drive/My Drive/google_cloud/data/SalesData/train.csv\")\n",
        "print(\"Total Records with header: \", trainRDD.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Total Records with header: ', 550069)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5L26SQgCw_d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4442bafb-a231-430b-c472-2422227fc1ee"
      },
      "source": [
        "print(\"\\nFirst Two Records Before Removing Header\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "First Two Records Before Removing Header\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Vpc9puCw_w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "49b20fa5-271f-4f54-d988-6a68a7768a10"
      },
      "source": [
        "header = trainRDD.first()\n",
        "header"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "u'User_ID,Product_ID,Gender,Age,Occupation,City_Category,Stay_In_Current_City_Years,Marital_Status,Product_Category_1,Product_Category_2,Product_Category_3,Purchase'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEPC5Q_FCw_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8555c24d-6e27-4be1-e351-fd759fc6b146"
      },
      "source": [
        "trainRDD = trainRDD.filter(lambda line: line != header)\n",
        "print(\"Total Records without header: \", trainRDD.count())\n",
        "print(\"\\nFirst Two Records After Removing Header\\n\")\n",
        "print(trainRDD.take(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Total Records without header: ', 550068)\n",
            "\n",
            "First Two Records After Removing Header\n",
            "\n",
            "[u'1000001,P00069042,F,0-17,10,A,2,0,3,,,8370', u'1000001,P00248942,F,0-17,10,A,2,0,1,6,14,15200']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiVAb2oVCxAG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0fa09b67-b776-4d57-d567-600cddaab3ab"
      },
      "source": [
        "# Split the data into individual columns\n",
        "splitRDD = trainRDD.map(lambda row:row.split(\",\"))\n",
        "print(\"\\nFirst Two Records After Split/Parsing\\n\")\n",
        "print(splitRDD.take(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "First Two Records After Split/Parsing\n",
            "\n",
            "[[u'1000001', u'P00069042', u'F', u'0-17', u'10', u'A', u'2', u'0', u'3', u'', u'', u'8370'], [u'1000001', u'P00248942', u'F', u'0-17', u'10', u'A', u'2', u'0', u'1', u'6', u'14', u'15200']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPdq9IyTCxAR"
      },
      "source": [
        "#### Create a dataframe for the above Data\n",
        "1. Define Schema\n",
        "2. Create dataframe using the above schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETL_qScRCxAV"
      },
      "source": [
        "#### Create Schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG11so_TCxAY"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "trainSchema = StructType([\n",
        "    StructField(\"User_ID\", StringType(), True),\n",
        "    StructField(\"Product_ID\", StringType(), True),\n",
        "    StructField(\"Gender\", StringType(), True),\n",
        "    StructField(\"Age\", StringType(), True),\n",
        "    StructField(\"Occupation\", StringType(), True),\n",
        "    StructField(\"City_Category\", StringType(), True),\n",
        "    StructField(\"Stay_In_Current_City_Years\",StringType(),True),\n",
        "    StructField(\"Marital_Status\", StringType(), True),\n",
        "    StructField(\"Product_Category_1\", StringType(), True),\n",
        "    StructField(\"Product_Category_2\", StringType(), True),\n",
        "    StructField(\"Product_Category_3\", StringType(), True),\n",
        "    StructField(\"Purchase\",StringType(),True)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCOZkWwwCxAl"
      },
      "source": [
        "#### Create DataFrame using toDF()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XAhNUvFCxAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d1ca9ce3-dd4f-4fa7-bfe3-fe0a65f76846"
      },
      "source": [
        "trainDF = splitRDD.toDF(schema = trainSchema)\n",
        "trainDF.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|                  |                  |    8370|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
            "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|                  |                  |    1422|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|                  |    1057|\n",
            "|1000002| P00285442|     M| 55+|        16|            C|                        4+|             0|                 8|                  |                  |    7969|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BAkG_-aCxA0"
      },
      "source": [
        "#### Create DataFrame using createDataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2BcKTNdCxA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "e318ae26-f6d6-46a7-b922-a3f5ae7ed27e"
      },
      "source": [
        "trainDF = spark.createDataFrame(data = splitRDD, schema=trainSchema)\n",
        "trainDF.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|                  |                  |    8370|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
            "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|                  |                  |    1422|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|                  |    1057|\n",
            "|1000002| P00285442|     M| 55+|        16|            C|                        4+|             0|                 8|                  |                  |    7969|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_-aaH1QCxBE"
      },
      "source": [
        "### 4. DataFrame Transformations & Actions\n",
        "\n",
        "### Transformations\n",
        "In Spark, the core data structures are immutable, meaning they cannot be changed after they’re created.\n",
        "<br> To “change” a DataFrame, you need to instruct Spark how you would like to modify it to do what you want.\n",
        "<br> These instructions are called transformations.\n",
        "<br> Transformations are the core of how you express your business logic using Spark.\n",
        "<br> Transformations are simply ways of specifying different series of data manipulation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX9CIV7uCxBH"
      },
      "source": [
        "#### Create a dataframe with one column containing 100 rows with values from 0 to 99."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCzT1P5ZCxBK"
      },
      "source": [
        "myRange = spark.range(100).toDF('number')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhRCp5M3CxBU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "973e753d-755a-4907-9fd0-4232712699b4"
      },
      "source": [
        "myRange.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|number|\n",
            "+------+\n",
            "|     0|\n",
            "|     1|\n",
            "|     2|\n",
            "|     3|\n",
            "|     4|\n",
            "|     5|\n",
            "|     6|\n",
            "|     7|\n",
            "|     8|\n",
            "|     9|\n",
            "+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY_VZcu-CxBg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bfc6fac-8709-45dc-c9fb-1864360b5c55"
      },
      "source": [
        "divisBy2 = myRange.where(\"number % 2 = 0\")\n",
        "divisBy2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[number: bigint]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyLxs4r6CxBq"
      },
      "source": [
        "Notice that these return no output. <br>This is because we specified only an abstract transformation, and Spark will not act on transformations until we call an action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ImgbGzOCxBt"
      },
      "source": [
        "### Actions\n",
        "Transformations allow us to build up our logical transformation plan. \n",
        "<br> To trigger the computation, we run an action.\n",
        "<br> An action instructs Spark to compute a result from a series of transformations. \n",
        "<br> The simplest action is show, which displays the records in the DataFrame\n",
        "\n",
        "#### There are 3 types of actions\n",
        "Actions to view data in the console\n",
        "<br>Actions to collect data \n",
        "<br>Actions to write to output data sources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ORpwASp-CxBw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "78d3a074-7340-4a2c-f9cd-4459796ff09e"
      },
      "source": [
        "divisBy2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|number|\n",
            "+------+\n",
            "|     0|\n",
            "|     2|\n",
            "|     4|\n",
            "|     6|\n",
            "|     8|\n",
            "|    10|\n",
            "|    12|\n",
            "|    14|\n",
            "|    16|\n",
            "|    18|\n",
            "|    20|\n",
            "|    22|\n",
            "|    24|\n",
            "|    26|\n",
            "|    28|\n",
            "|    30|\n",
            "|    32|\n",
            "|    34|\n",
            "|    36|\n",
            "|    38|\n",
            "+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atMvlhOmCxB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11b2e455-3429-41f7-a705-4723cbef5511"
      },
      "source": [
        "divisBy2.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "h0M_1V7-CxCJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8f8cd29c-bb8d-4a44-d8f1-34adfb3396c1"
      },
      "source": [
        "trainDF.take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(User_ID=u'1000001', Product_ID=u'P00069042', Gender=u'F', Age=u'0-17', Occupation=u'10', City_Category=u'A', Stay_In_Current_City_Years=u'2', Marital_Status=u'0', Product_Category_1=u'3', Product_Category_2=u'', Product_Category_3=u'', Purchase=u'8370'),\n",
              " Row(User_ID=u'1000001', Product_ID=u'P00248942', Gender=u'F', Age=u'0-17', Occupation=u'10', City_Category=u'A', Stay_In_Current_City_Years=u'2', Marital_Status=u'0', Product_Category_1=u'1', Product_Category_2=u'6', Product_Category_3=u'14', Purchase=u'15200')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lQhHj-ufCxCW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f1d736ba-9d10-4d1b-a16f-51a415b66cfb"
      },
      "source": [
        "trainDF.show(4,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender|Age |Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001|P00069042 |F     |0-17|10        |A            |2                         |0             |3                 |                  |                  |8370    |\n",
            "|1000001|P00248942 |F     |0-17|10        |A            |2                         |0             |1                 |6                 |14                |15200   |\n",
            "|1000001|P00087842 |F     |0-17|10        |A            |2                         |0             |12                |                  |                  |1422    |\n",
            "|1000001|P00085442 |F     |0-17|10        |A            |2                         |0             |12                |14                |                  |1057    |\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOFD6VwyCxCk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ea9aef7-8db1-4842-fd09-eb55d66e1df6"
      },
      "source": [
        "trainDF.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "550068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHvbWot8CxCx"
      },
      "source": [
        "### 5. Reading a CSV file into a DataFrame "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0bkArhdCxC1"
      },
      "source": [
        "path = \"drive/My Drive/google_cloud/data/SalesData/train.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuLza8r4CxDB"
      },
      "source": [
        "trainDF = spark.read.csv(path=path,header=True,schema=trainSchema,sep=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJFXLGdACxDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "85a4a5a2-fc6b-448b-b8c5-94785d99e01f"
      },
      "source": [
        "trainDF.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(User_ID=u'1000001', Product_ID=u'P00069042', Gender=u'F', Age=u'0-17', Occupation=u'10', City_Category=u'A', Stay_In_Current_City_Years=u'2', Marital_Status=u'0', Product_Category_1=u'3', Product_Category_2=None, Product_Category_3=None, Purchase=u'8370'),\n",
              " Row(User_ID=u'1000001', Product_ID=u'P00248942', Gender=u'F', Age=u'0-17', Occupation=u'10', City_Category=u'A', Stay_In_Current_City_Years=u'2', Marital_Status=u'0', Product_Category_1=u'1', Product_Category_2=u'6', Product_Category_3=u'14', Purchase=u'15200'),\n",
              " Row(User_ID=u'1000001', Product_ID=u'P00087842', Gender=u'F', Age=u'0-17', Occupation=u'10', City_Category=u'A', Stay_In_Current_City_Years=u'2', Marital_Status=u'0', Product_Category_1=u'12', Product_Category_2=None, Product_Category_3=None, Purchase=u'1422'),\n",
              " Row(User_ID=u'1000001', Product_ID=u'P00085442', Gender=u'F', Age=u'0-17', Occupation=u'10', City_Category=u'A', Stay_In_Current_City_Years=u'2', Marital_Status=u'0', Product_Category_1=u'12', Product_Category_2=u'14', Product_Category_3=None, Purchase=u'1057'),\n",
              " Row(User_ID=u'1000002', Product_ID=u'P00285442', Gender=u'M', Age=u'55+', Occupation=u'16', City_Category=u'C', Stay_In_Current_City_Years=u'4+', Marital_Status=u'0', Product_Category_1=u'8', Product_Category_2=None, Product_Category_3=None, Purchase=u'7969')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "975DcvHLCxDp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "5baa266d-b424-4364-cc10-abbfffbf544d"
      },
      "source": [
        "trainDF.show(5,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender|Age |Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001|P00069042 |F     |0-17|10        |A            |2                         |0             |3                 |null              |null              |8370    |\n",
            "|1000001|P00248942 |F     |0-17|10        |A            |2                         |0             |1                 |6                 |14                |15200   |\n",
            "|1000001|P00087842 |F     |0-17|10        |A            |2                         |0             |12                |null              |null              |1422    |\n",
            "|1000001|P00085442 |F     |0-17|10        |A            |2                         |0             |12                |14                |null              |1057    |\n",
            "|1000002|P00285442 |M     |55+ |16        |C            |4+                        |0             |8                 |null              |null              |7969    |\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OSSm3DeCxD2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f87e702a-5a8f-48bf-be91-a04e542bd3b6"
      },
      "source": [
        "trainDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- User_ID: string (nullable = true)\n",
            " |-- Product_ID: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Occupation: string (nullable = true)\n",
            " |-- City_Category: string (nullable = true)\n",
            " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
            " |-- Marital_Status: string (nullable = true)\n",
            " |-- Product_Category_1: string (nullable = true)\n",
            " |-- Product_Category_2: string (nullable = true)\n",
            " |-- Product_Category_3: string (nullable = true)\n",
            " |-- Purchase: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K0u_C5CCxEE"
      },
      "source": [
        "#### Getting the  shape of the spark data frame\n",
        "* As such there is no shape command directly in spark we need to get it from the length of columns and \n",
        "  count of records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mfQUXy-rCxEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6576b5ae-3cbe-4af7-a53c-5a583c0afb4f"
      },
      "source": [
        "## To Count the number of rows in DataFrame\n",
        "print('Total records count in train dataset is {}'.format(trainDF.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total records count in train dataset is 550068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "WiV1Y6k4CxES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a82a48de-9bca-4405-8893-b2455456b139"
      },
      "source": [
        "## Columns count and column names\n",
        "print(\"Total Columns count in train dataset is {}\".format(len(trainDF.columns)))\n",
        "print(\"\\n\\nColumns in train dataset are: {} \\n\".format(trainDF.columns))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Columns count in train dataset is 12\n",
            "\n",
            "\n",
            "Columns in train dataset are: ['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3', 'Purchase'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlHGY3PsCxEb"
      },
      "source": [
        "### 6. Verify Schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laVAY2nZCxEd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3e93ddbb-f1ad-4898-c086-fa17b4e36846"
      },
      "source": [
        "## Print Schema\n",
        "trainDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- User_ID: string (nullable = true)\n",
            " |-- Product_ID: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Occupation: string (nullable = true)\n",
            " |-- City_Category: string (nullable = true)\n",
            " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
            " |-- Marital_Status: string (nullable = true)\n",
            " |-- Product_Category_1: string (nullable = true)\n",
            " |-- Product_Category_2: string (nullable = true)\n",
            " |-- Product_Category_3: string (nullable = true)\n",
            " |-- Purchase: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qmq0hifCxEs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5a31a365-bb88-49fa-df5c-77914ca3b613"
      },
      "source": [
        "trainDF.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('User_ID', 'string'),\n",
              " ('Product_ID', 'string'),\n",
              " ('Gender', 'string'),\n",
              " ('Age', 'string'),\n",
              " ('Occupation', 'string'),\n",
              " ('City_Category', 'string'),\n",
              " ('Stay_In_Current_City_Years', 'string'),\n",
              " ('Marital_Status', 'string'),\n",
              " ('Product_Category_1', 'string'),\n",
              " ('Product_Category_2', 'string'),\n",
              " ('Product_Category_3', 'string'),\n",
              " ('Purchase', 'string')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGVtXg97CxE0"
      },
      "source": [
        "#### Getting the Columns from the SparkDataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp7bDRJwCxE8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5cfc1e98-13e0-4054-b4af-71956c88f8d2"
      },
      "source": [
        "trainDF.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['User_ID',\n",
              " 'Product_ID',\n",
              " 'Gender',\n",
              " 'Age',\n",
              " 'Occupation',\n",
              " 'City_Category',\n",
              " 'Stay_In_Current_City_Years',\n",
              " 'Marital_Status',\n",
              " 'Product_Category_1',\n",
              " 'Product_Category_2',\n",
              " 'Product_Category_3',\n",
              " 'Purchase']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9UGQOUtCxFG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f7aef4c-36f2-49f6-bfba-ec87df873338"
      },
      "source": [
        "type(trainDF.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6vKG3-ECxFP"
      },
      "source": [
        "### 7.To Show first n observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-jYcRh4CxFS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d48ef86f-d8a1-4b2e-95d5-0b0a8395c6d2"
      },
      "source": [
        "## Use head operation to see first n observations (say, 2 observations). \n",
        "## Head operation in PySpark is similar to head operation in Pandas.\n",
        "trainDF.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(User_ID=u'1000001', Product_ID=u'P00069042', Gender=u'F', Age=u'0-17', Occupation=u'10', City_Category=u'A', Stay_In_Current_City_Years=u'2', Marital_Status=u'0', Product_Category_1=u'3', Product_Category_2=None, Product_Category_3=None, Purchase=u'8370'),\n",
              " Row(User_ID=u'1000001', Product_ID=u'P00248942', Gender=u'F', Age=u'0-17', Occupation=u'10', City_Category=u'A', Stay_In_Current_City_Years=u'2', Marital_Status=u'0', Product_Category_1=u'1', Product_Category_2=u'6', Product_Category_3=u'14', Purchase=u'15200')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJmqbq0TCxFi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "11e2ec95-39ae-4122-f68c-9cdaf5862656"
      },
      "source": [
        "## Above results are comprised of row like format. \n",
        "## To see the result in more interactive manner (rows under the columns), Use the show operation. \n",
        "## Show operation on train and take first 5 rows of it. \n",
        "trainDF.show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtO0ttWFCxGA"
      },
      "source": [
        "### 8.Summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Jm2oyZl2CxGG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8d15453a-a0c7-4e6b-f963-6f607da4fa7a"
      },
      "source": [
        "## To get the summary statistics (mean, standard deviance, min ,max , count) of numerical columns in a DataFrame\n",
        "trainDF.describe().show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
            "|summary|User_ID           |Product_ID|Gender|Age   |Occupation       |City_Category|Stay_In_Current_City_Years|Marital_Status     |Product_Category_1|Product_Category_2|Product_Category_3|Purchase         |\n",
            "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
            "|count  |550068            |550068    |550068|550068|550068           |550068       |550068                    |550068             |550068            |376430            |166821            |550068           |\n",
            "|mean   |1003028.8424013031|null      |null  |null  |8.076706879876669|null         |1.468494139793958         |0.40965298835780306|5.404270017525106 |9.842329251122386 |12.668243206790512|9263.968712959126|\n",
            "|stddev |1727.5915855313747|null      |null  |null  |6.522660487341741|null         |0.9890866807573103        |0.4917701263173315 |3.936211369201365 |5.086589648693497 |4.125337631575274 |5023.065393820575|\n",
            "|min    |1000001           |P00000142 |F     |0-17  |0                |A            |0                         |0                  |1                 |10                |10                |10000            |\n",
            "|max    |1006040           |P0099942  |M     |55+   |9                |C            |4+                        |1                  |9                 |9                 |9                 |9999             |\n",
            "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "U5nl_iVPCxGR"
      },
      "source": [
        "## Check what happens when we specify the name of a categorical / String columns in describe operation.\n",
        "## describe operation is working for String type column but the output for mean, stddev are null and \n",
        "## min & max values are calculated based on ASCII value of categories.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dANkRILMCxGe"
      },
      "source": [
        "### 9. a. Adding Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DPAjRVpPCxGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "17b8db62-7b15-47b4-f5ae-16ad0a0fef26"
      },
      "source": [
        "## More Formal way\n",
        "from pyspark.sql.functions import lit\n",
        "trainDF.withColumn(\"Year\", lit(\"2019\")).show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|Year|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----+\n",
            "|1000001| P00051842|     F|0-17|        10|            A|                         2|             0|                 4|                 8|              null|    2849|2019|\n",
            "|1000001| P00059442|     F|0-17|        10|            A|                         2|             0|                 6|                 8|                16|   16622|2019|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "6P6eYNbFCxHK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f6ae4d32-7692-4fd5-9bb9-41f82246fe87"
      },
      "source": [
        "tempDF = trainDF.withColumn(\"SameCategoryCode\", \n",
        "trainDF[\"Product_Category_1\"] == trainDF[\"Product_Category_2\"])\n",
        "tempDF.show(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----------------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|SameCategoryCode|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----------------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|            null|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|           false|\n",
            "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|            null|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|           false|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXu770mZCxHi"
      },
      "source": [
        "### 9.b.Renaming Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "_yDzhHtyCxHp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2407e791-6caf-4a52-b4db-ed200f934d41"
      },
      "source": [
        "tempDF.withColumnRenamed(\"SameCategoryCode\", \"SimilarCategory\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+---------------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|SimilarCategory|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+---------------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|           null|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          false|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+---------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtMwzX-hCxIC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "22c7b963-7117-402e-e70d-e4b9b6184bde"
      },
      "source": [
        "tempDF.show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----------------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|SameCategoryCode|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----------------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|            null|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|           false|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne6iUvniCxIa"
      },
      "source": [
        "### 9.c.Removing Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "LDvwJax4CxIc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "3c1c7689-1e0d-41db-90f2-3f9535fc4592"
      },
      "source": [
        "tempDF.drop(\"SameCategoryCode\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q978vCagCxI2"
      },
      "source": [
        "### 10. Changing a Column’s Type (cast)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "huugv86ZCxI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "aae09722-ae18-4333-e6e3-2a4db09e9015"
      },
      "source": [
        "trainDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- User_ID: string (nullable = true)\n",
            " |-- Product_ID: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Occupation: string (nullable = true)\n",
            " |-- City_Category: string (nullable = true)\n",
            " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
            " |-- Marital_Status: string (nullable = true)\n",
            " |-- Product_Category_1: string (nullable = true)\n",
            " |-- Product_Category_2: string (nullable = true)\n",
            " |-- Product_Category_3: string (nullable = true)\n",
            " |-- Purchase: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Hztr-QCxJD"
      },
      "source": [
        "trainDF = trainDF.withColumn(\"Purchase\",trainDF.Purchase.cast(IntegerType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOeHKEj0CxJX"
      },
      "source": [
        "### 11. Splitting the data into Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnOfQGKDCxJc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c63ac973-4b2e-40f9-9c2e-0158c807f3a8"
      },
      "source": [
        "trainDF,testDF = trainDF.randomSplit([0.7, 0.3], seed=1234)\n",
        "print(trainDF.count())\n",
        "print(testDF.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "385465\n",
            "164603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9uOvjWoCxJ4"
      },
      "source": [
        "### 12. Working with Nulls in Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF3rVbTgCxJ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "836af054-4344-463b-ed26-f83dcb274298"
      },
      "source": [
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "trainDF.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in trainDF.columns]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+---+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender|Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+---+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|      0|         0|     0|  0|         0|            0|                         0|             0|                 0|            121619|            268621|       0|\n",
            "+-------+----------+------+---+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSH0B8THCxKA"
      },
      "source": [
        "#### To drop the all rows with null value?\n",
        "##### Use **dropna()** operation. \n",
        "  To drop row from the DataFrame it consider three options.\n",
        "* **how** – ‘any’ or ‘all’. If ‘any’, drop a row if it contains any nulls. If ‘all’, drop a row only if all its values are null.\n",
        "\n",
        "* **thresh** – int, default None If specified, drop rows that have less than thresh non-null values.This overwrites the how parameter.\n",
        "\n",
        "* **subset** – optional list of column names to consider.\n",
        "\n",
        "#### Drop null rows in train with default parameters and count the rows in output DataFrame. \n",
        "#### Default options are any, None, None for how, thresh, subset respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LId2YPvNCxKD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6ecdbcaf-79fc-4712-9b04-5f68bfac980e"
      },
      "source": [
        "print(trainDF.dropna().count())\n",
        "print(trainDF.na.drop().count())\n",
        "print(trainDF.na.drop(\"any\").count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116844\n",
            "116844\n",
            "116844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": true,
        "id": "ly1RnCoTCxKU"
      },
      "source": [
        "#### To replace the null values in DataFrame with constant number\n",
        "#### Use **fillna()** operation. \n",
        "\n",
        " The fillna will take two parameters to fill the null values.\n",
        "* **value**:\n",
        "    - It will take a dictionary to specify which column will replace with which value.A value (int , float, string) for all columns.\n",
        "* **subset**: Specify some selected columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "c4EqsqcBCxKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "7ac13e93-bbda-41df-b667-0662d6642ee7"
      },
      "source": [
        "##Fill ‘-1’ inplace of null values in train DataFrame.\n",
        "trainDF.fillna(-1).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00051842|     F|0-17|        10|            A|                         2|             0|                 4|                 8|              null|    2849|\n",
            "|1000001| P00059442|     F|0-17|        10|            A|                         2|             0|                 6|                 8|                16|   16622|\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|\n",
            "|1000001| P00085942|     F|0-17|        10|            A|                         2|             0|                 2|                 4|                 8|   12842|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A63RO0JCxKj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62ff9f68-0c68-44be-bde9-2ad98154f5f4"
      },
      "source": [
        "## Filling with different values for different columns\n",
        "fill_cols_vals = {\n",
        "\"Gender\": 'M',\n",
        "\"Purchase\" : 999999\n",
        "}\n",
        "trainDF.na.fill(fill_cols_vals).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "385465"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDNIHIm9CxKs"
      },
      "source": [
        "### 13. Distinct Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF_ze0H1CxKw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3024455a-18e4-4581-8234-4f7d807e9f60"
      },
      "source": [
        "## To find the number of distinct product in train and test datasets\n",
        "## To calculate the number of distinct products in train and test datasets apply distinct operation.\n",
        "print(\"Distinct values in Product_ID's in train dataset are {}\".format(trainDF.select('Product_ID').distinct().count()))\n",
        "print(\"Distinct values in Product_ID's in test dataset are {}\".format(testDF.select('Product_ID').distinct().count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distinct values in Product_ID's in train dataset are 3573\n",
            "Distinct values in Product_ID's in test dataset are 3421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g67PGS0nCxK5"
      },
      "source": [
        "#### Differences in two columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBuDGWV1CxK7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a2195c2b-e270-45bf-e2e7-b974d8aa0738"
      },
      "source": [
        "## From the above we can see the train file has more categories than test file. \n",
        "## Let us check what are the categories for Product_ID, which are in test file but not in train file by \n",
        "## applying subtract operation.\n",
        "## We can do the same for all categorical features.\n",
        "diff_cat_in_test_train=testDF.select('Product_ID').subtract(trainDF.select('Product_ID'))\n",
        "print(\"Count of Product_ID's there in test dataset but not train dataset are {}\".format(diff_cat_in_test_train.count()))\n",
        "\n",
        "\n",
        "print(\"Count of Product_ID's there in train dataset but not test dataset are {}\".format(diff_cat_in_train_test.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Product_ID's there in test dataset but not train dataset are 58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-cbff4f72b889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Count of Product_ID's there in train dataset but not test dataset are {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_cat_in_train_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'diff_cat_in_train_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdIIiunLCxLT"
      },
      "source": [
        "### 14. Using Spark SQL \n",
        "With Spark SQL, you can register any DataFrame as a table or view (a temporary table) and query it using pure SQL. \n",
        "<br>There is no performance difference between writing SQL queries or writing DataFrame code, <br>they both “compile” to the same underlying plan that we specify in DataFrame code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU4AASnlCxLZ"
      },
      "source": [
        "## Create view/table\n",
        "trainDF.createOrReplaceTempView(\"trainDFTable\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jY08z3BiCxLj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a62ec168-5337-4ea4-a809-0ec0072ae794"
      },
      "source": [
        "## Verify Table\n",
        "spark.sql(\"SELECT * FROM trainDFTable LIMIT 2\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00051842|     F|0-17|        10|            A|                         2|             0|                 4|                 8|              null|    2849|\n",
            "|1000001| P00059442|     F|0-17|        10|            A|                         2|             0|                 6|                 8|                16|   16622|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIGySExFCxLt"
      },
      "source": [
        "#### Column References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oT_8GP5CxLv"
      },
      "source": [
        "#### Select & SelectExpr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "pt-FayCeCxLx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "51c79b9d-73c0-4517-c7d1-2cbdab2189fb"
      },
      "source": [
        "## Multiple ways of referring a column in a dataframe\n",
        "from pyspark.sql.functions import expr, col, column\n",
        "\n",
        "trainDF.select(expr(\"User_ID AS userID\") , col(\"User_ID\"), \n",
        "               column(\"User_ID\"), \"User_ID\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+-------+-------+\n",
            "| userID|User_ID|User_ID|User_ID|\n",
            "+-------+-------+-------+-------+\n",
            "|1000001|1000001|1000001|1000001|\n",
            "|1000001|1000001|1000001|1000001|\n",
            "+-------+-------+-------+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHVuzYMaCxL4"
      },
      "source": [
        "#### Pandas dot notation doesn't work here "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjg2hX0qCxL8"
      },
      "source": [
        "result = trainDF.User_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6MH2MjvCxMI"
      },
      "source": [
        "This will save/assign a column name to the newly created variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-068q-6vCxMM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "230ed542-c598-43d5-8b34-66c111daaf6e"
      },
      "source": [
        "# select content from the above column\n",
        "trainDF.select(result).show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+\n",
            "|User_ID|\n",
            "+-------+\n",
            "|1000001|\n",
            "|1000001|\n",
            "+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brhS4yH0CxMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ee5a9120-63da-4bbd-8f61-df711f07fb0b"
      },
      "source": [
        "spark.sql(\"SELECT User_ID AS userID FROM trainDFTable\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+\n",
            "| userID|\n",
            "+-------+\n",
            "|1000001|\n",
            "|1000001|\n",
            "+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLyxP0GQCxM4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a6976625-a0af-4bcb-934b-9913531cc6a2"
      },
      "source": [
        "trainDF.selectExpr(\"User_ID AS userID\", \"Product_ID AS productID\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+---------+\n",
            "| userID|productID|\n",
            "+-------+---------+\n",
            "|1000001|P00051842|\n",
            "|1000001|P00059442|\n",
            "+-------+---------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgBV311iCxNB"
      },
      "source": [
        "#### Converting to Spark Types (Literals)\n",
        "Sometimes we need to pass explicit values into Spark that aren’t a new column but are just a value in all the rows. This might be a constant value or something we’ll need to compare to later on. The way we do this is through literals. \n",
        "This is basically a translation from a given programming language’s literal value to one that Spark understands. \n",
        "Literals are expressions and can be used in the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWmOF-xUCxNC"
      },
      "source": [
        "from pyspark.sql.functions import lit\n",
        "trainDF.select(\"*\", lit(1).alias('One')).show(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xIoMQgOjCxNI"
      },
      "source": [
        "## In SQL, literals are just the specific value.\n",
        "trainDF.createOrReplaceTempView('trainDFTable')\n",
        "spark.sql(\"SELECT *, 2019 as Year FROM trainDFTable LIMIT 2\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xmsOK56CxNR"
      },
      "source": [
        "#### Pair wise Frequencies - Crosstab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "gAL4uxr-CxNU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "05e62582-9da1-4789-9583-13c7ee1df151"
      },
      "source": [
        "## To calculate pair wise frequency of categorical columns\n",
        "## Use crosstab operation on DataFrame to calculate the pair wise frequency of columns. \n",
        "## Apply crosstab operation on ‘Age’ and ‘Gender’ columns of train DataFrame.\n",
        "trainDF.crosstab('Gender', 'Age').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----+-----+------+-----+-----+-----+-----+\n",
            "|Gender_Age|0-17|18-25| 26-35|36-45|46-50|51-55|  55+|\n",
            "+----------+----+-----+------+-----+-----+-----+-----+\n",
            "|         M|7027|52744|118248|57967|22722|20053|11541|\n",
            "|         F|3548|17192| 35670|19017| 9191| 6962| 3583|\n",
            "+----------+----+-----+------+-----+-----+-----+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voXqFYLdCxNg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_c8OAA9wCxNs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "92472625-516f-47d4-849a-bbeba3d40b52"
      },
      "source": [
        "spark.sql(\"\"\"select Age,\n",
        "    sum(case when Gender = 'F' then 1 else 0 end) F,\n",
        "    sum(case when Gender = 'M' then 1 else 0 end) M\n",
        "from trainDFTable\n",
        "group by Age\"\"\").show()\n",
        "\n",
        "# spark.sql(\"\"\"select Age,\n",
        "#     count(*) total,\n",
        "#     sum(case when Gender = 'F' then 1 else 0 end) F,\n",
        "#     sum(case when Gender = 'M' then 1 else 0 end) M\n",
        "# from trainDFTable\n",
        "# group by Age\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+------+\n",
            "|  Age|    F|     M|\n",
            "+-----+-----+------+\n",
            "|18-25|17192| 52744|\n",
            "|26-35|35670|118248|\n",
            "| 0-17| 3548|  7027|\n",
            "|46-50| 9191| 22722|\n",
            "|51-55| 6962| 20053|\n",
            "|36-45|19017| 57967|\n",
            "|  55+| 3583| 11541|\n",
            "+-----+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKDPVZMcCxN4"
      },
      "source": [
        "#### Removing Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JZCk7oO5CxN7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "18131e7c-3fa0-44b8-bdef-9d79c0e6c04b"
      },
      "source": [
        "##To get the DataFrame without any duplicate rows of given a DataFrame\n",
        "##Use dropDuplicates operation to drop the duplicate rows of a DataFrame. \n",
        "## In this command, performing this on two columns Age and Gender of train dataset and \n",
        "## Get the all unique rows for these two columns.\n",
        "trainDF.select('Age','Gender').dropDuplicates().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|  Age|Gender|\n",
            "+-----+------+\n",
            "|51-55|     F|\n",
            "|18-25|     M|\n",
            "| 0-17|     F|\n",
            "|46-50|     M|\n",
            "|18-25|     F|\n",
            "|  55+|     M|\n",
            "|  55+|     F|\n",
            "|36-45|     M|\n",
            "|26-35|     F|\n",
            "| 0-17|     M|\n",
            "|36-45|     F|\n",
            "|51-55|     M|\n",
            "|26-35|     M|\n",
            "|46-50|     F|\n",
            "+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBjBm6P4CxOG"
      },
      "source": [
        "#### Filtering the rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ePLZ3al4CxOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "171fde57-8387-4794-a80e-396ed8301bfc"
      },
      "source": [
        "## To filter the rows in train dataset which has Purchases more than 15000\n",
        "## apply the filter operation on Purchase column in train DataFrame \n",
        "## to filter out the rows with values more than 15000. \n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(trainDF.Purchase > 15000).count()))\n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(col(\"Purchase\") > 15000).count()))\n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(column(\"Purchase\") > 15000).count()))\n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(expr(\"Purchase\") > 15000).count()))\n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(trainDF[\"Purchase\"] > 15000).count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of rows where Purchase Amount more than 15000 are 77137\n",
            "Count of rows where Purchase Amount more than 15000 are 77137\n",
            "Count of rows where Purchase Amount more than 15000 are 77137\n",
            "Count of rows where Purchase Amount more than 15000 are 77137\n",
            "Count of rows where Purchase Amount more than 15000 are 77137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rDJvdj2CxOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5e368ddb-6f22-4d13-b961-8e1a48e1230e"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT \n",
        "COUNT(*) AS Count\n",
        "FROM trainDFTable\n",
        "WHERE Purchase > 15000\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|Count|\n",
            "+-----+\n",
            "|77137|\n",
            "+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2RnF5msiCxOu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "785faa48-f827-4b6e-aded-d93007353e59"
      },
      "source": [
        "trainDF.where(\"Purchase > 15000\").where(\"Gender = 'F'\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml8rr8oDCxPD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82fd5513-e2c8-4933-c89e-9e353e92ede4"
      },
      "source": [
        "trainDF.filter(\"Purchase > 15000\").where(\"Gender = 'F'\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKn-VzuMCxPQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3860624b-d5db-4a25-c241-0651433044ec"
      },
      "source": [
        "trainDF.where((col(\"Purchase\") > 15000) & (col(\"Gender\") == 'F')).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPrcxcq2CxPg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05ac7233-a6ac-43cf-d437-875ed366040d"
      },
      "source": [
        "trainDF.filter((col(\"Purchase\") > 15000) & (col(\"Gender\") == 'F')).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC9zujj6CxPo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5267d4ad-70f8-45a9-c41c-ccc2a15be2a9"
      },
      "source": [
        "spark.sql(\"SELECT * FROM trainDFTable WHERE Purchase > 15000 AND Gender = 'F'\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KgwdIczCxPu"
      },
      "source": [
        "### 15. Aggregations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBXADrjQCxPv"
      },
      "source": [
        "#### Count Distinct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "O2ikuK7TCxPx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1f5078c1-a35a-4726-b7c1-da9a5923e542"
      },
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "trainDF.select(countDistinct(\"Age\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+\n",
            "|count(DISTINCT Age)|\n",
            "+-------------------+\n",
            "|                  7|\n",
            "+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ph60368CxP9"
      },
      "source": [
        "#### Approximate Count Distinct\n",
        "* **Parameters:**\n",
        "    * col - Name of the column\n",
        "    * rsd – maximum estimation error allowed (default = 0.05)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XB2uCIuCxQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6c451bc1-ef4b-491c-ac36-c37aa6f54bc1"
      },
      "source": [
        "from pyspark.sql.functions import approx_count_distinct\n",
        "trainDF.select(approx_count_distinct(col=\"Age\", rsd=0.1)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------+\n",
            "|approx_count_distinct(Age)|\n",
            "+--------------------------+\n",
            "|                         7|\n",
            "+--------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqHvRwT2CxQR"
      },
      "source": [
        "#### First and Last"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xUESF2AmCxQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "56c9b12c-7019-4ced-dbe9-073a6d34dbea"
      },
      "source": [
        "from pyspark.sql.functions import first, last\n",
        "trainDF.select(first(\"Product_ID\", ignorenulls = True), last(\"Product_ID\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+-----------------------+\n",
            "|first(Product_ID, true)|last(Product_ID, false)|\n",
            "+-----------------------+-----------------------+\n",
            "|              P00051842|              P00349442|\n",
            "+-----------------------+-----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvrBce7wCxQm"
      },
      "source": [
        "#### Min and Max"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Sp7sLntiCxQt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3f928c9d-4ec6-47f1-c387-841afd9f4362"
      },
      "source": [
        "from pyspark.sql.functions import min, max\n",
        "trainDF.select(min(\"Purchase\"), max(\"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+-------------+\n",
            "|min(Purchase)|max(Purchase)|\n",
            "+-------------+-------------+\n",
            "|           12|        23961|\n",
            "+-------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49HlwnsJCxQ4"
      },
      "source": [
        "#### Sum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-4HnKj1CxQ6"
      },
      "source": [
        "from pyspark.sql.functions import sum\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKnAry6SCxRA"
      },
      "source": [
        "#### sumDistinct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kye84VbxCxRB"
      },
      "source": [
        "from pyspark.sql.functions import sumDistinct\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMqn-uUdCxRV"
      },
      "source": [
        "#### Avg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yPOipdBCxR4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "93b8976b-3328-41d1-82ff-3bba2d2e9da0"
      },
      "source": [
        "from pyspark.sql.functions import sum, count, avg, expr\n",
        "\n",
        "trainDF.select(\n",
        "    count(\"Purchase\").alias(\"total_transactions\"),\n",
        "    sum(\"Purchase\").alias(\"total_purchases\"),\n",
        "    avg(\"Purchase\").alias(\"avg_purchases\"),\n",
        "    expr(\"mean(Purchase)\").alias(\"mean_purchases\"))\\\n",
        "  .selectExpr(\n",
        "    \"total_purchases/total_transactions\",\n",
        "    \"avg_purchases\",\n",
        "    \"mean_purchases\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------+-----------------+-----------------+\n",
            "|(total_purchases / total_transactions)|    avg_purchases|   mean_purchases|\n",
            "+--------------------------------------+-----------------+-----------------+\n",
            "|                     9252.862885086843|9252.862885086843|9252.862885086843|\n",
            "+--------------------------------------+-----------------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkJ9AjNECxTB"
      },
      "source": [
        "#### Variance and Standard Deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8l7aKnqzCxTF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cb2b7692-5d8a-4b3e-8dca-fff3b81c31f0"
      },
      "source": [
        "from pyspark.sql.functions import var_pop, stddev_pop\n",
        "from pyspark.sql.functions import var_samp, stddev_samp\n",
        "\n",
        "trainDF.select(var_pop(\"Purchase\"), var_samp(\"Purchase\"),\n",
        "  stddev_pop(\"Purchase\"), stddev_samp(\"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+---------------------+\n",
            "|   var_pop(Purchase)|  var_samp(Purchase)|stddev_pop(Purchase)|stddev_samp(Purchase)|\n",
            "+--------------------+--------------------+--------------------+---------------------+\n",
            "|2.5196570178942546E7|2.5196635545799576E7|   5019.618529225358|    5019.625040359048|\n",
            "+--------------------+--------------------+--------------------+---------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CUT0OU8pCxTb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c0ea733d-f8cb-40ec-f120-21a49b362242"
      },
      "source": [
        "spark.sql(\"\"\"SELECT var_pop(Purchase), var_samp(Purchase),\n",
        "             stddev_pop(Purchase), stddev_samp(Purchase)\n",
        "             FROM trainDFTable\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------+----------------------------------+------------------------------------+-------------------------------------+\n",
            "|var_pop(CAST(Purchase AS DOUBLE))|var_samp(CAST(Purchase AS DOUBLE))|stddev_pop(CAST(Purchase AS DOUBLE))|stddev_samp(CAST(Purchase AS DOUBLE))|\n",
            "+---------------------------------+----------------------------------+------------------------------------+-------------------------------------+\n",
            "|             2.5196570178942546E7|              2.5196635545799576E7|                   5019.618529225358|                    5019.625040359048|\n",
            "+---------------------------------+----------------------------------+------------------------------------+-------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DslhTPfCxTr"
      },
      "source": [
        "#### skewness and kurtosis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2WMpp6-ICxTw"
      },
      "source": [
        "from pyspark.sql.functions import skewness, kurtosis\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_77I-S_rCxT7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ff0a9eb9-1cbe-41d5-a599-f1184dc2d942"
      },
      "source": [
        "spark.sql(\"\"\"SELECT skewness(Purchase), kurtosis(Purchase)\n",
        "             FROM trainDFTable\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------+----------------------------------+\n",
            "|skewness(CAST(Purchase AS DOUBLE))|kurtosis(CAST(Purchase AS DOUBLE))|\n",
            "+----------------------------------+----------------------------------+\n",
            "|                0.6011891058033598|               -0.3332972102207403|\n",
            "+----------------------------------+----------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9oDUz9TCxUG"
      },
      "source": [
        "#### Covariance and Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sw5cPtICxUJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "12623074-f6e7-418c-e5cf-20f71fa5525d"
      },
      "source": [
        "from pyspark.sql.functions import corr, covar_pop, covar_samp\n",
        "trainDF.select(corr(\"Product_Category_1\", \"Purchase\"), covar_samp(\"Product_Category_1\", \"Purchase\"),\n",
        "    covar_pop(\"Product_Category_1\", \"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------+----------------------------------------+---------------------------------------+\n",
            "|corr(Product_Category_1, Purchase)|covar_samp(Product_Category_1, Purchase)|covar_pop(Product_Category_1, Purchase)|\n",
            "+----------------------------------+----------------------------------------+---------------------------------------+\n",
            "|               -0.3441352558130045|                      -6799.583767801264|                      -6799.56612785012|\n",
            "+----------------------------------+----------------------------------------+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hj2_HuxECxUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "469a21d0-d893-4170-f824-3d7e00813ed7"
      },
      "source": [
        "spark.sql(\"\"\"SELECT corr(Product_Category_1, Purchase), covar_samp(Product_Category_1, Purchase),\n",
        "             covar_pop(Product_Category_1, Purchase)\n",
        "             FROM trainDFTable\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------+------------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
            "|corr(CAST(Product_Category_1 AS DOUBLE), CAST(Purchase AS DOUBLE))|covar_samp(CAST(Product_Category_1 AS DOUBLE), CAST(Purchase AS DOUBLE))|covar_pop(CAST(Product_Category_1 AS DOUBLE), CAST(Purchase AS DOUBLE))|\n",
            "+------------------------------------------------------------------+------------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
            "|                                               -0.3441352558130045|                                                      -6799.583767801264|                                                      -6799.56612785012|\n",
            "+------------------------------------------------------------------+------------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPji5VjiCxUg"
      },
      "source": [
        "#### Complex Aggregations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_dEvI0iCxUr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9f82ee3a-c4ba-43bc-cdb7-411b203f1c83"
      },
      "source": [
        "from pyspark.sql.functions import collect_set, collect_list\n",
        "trainDF.agg(collect_set(\"Age\"), collect_list(\"Age\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|    collect_set(Age)|   collect_list(Age)|\n",
            "+--------------------+--------------------+\n",
            "|[55+, 51-55, 0-17...|[0-17, 0-17, 0-17...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSFvhRBeF_d"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nSAkdW6yCxU4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6ea7e0b4-3f80-4dd8-8ede-50b11e44e2a1"
      },
      "source": [
        "spark.sql(\"\"\"SELECT collect_set(Age), collect_list(Age) FROM trainDFTable\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|    collect_set(Age)|   collect_list(Age)|\n",
            "+--------------------+--------------------+\n",
            "|[55+, 51-55, 0-17...|[0-17, 0-17, 0-17...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpPKEFT3CxVb"
      },
      "source": [
        "#### Grouping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emPGLkPuCxVh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "82002123-b605-4e3d-f40f-9ce82d9af69d"
      },
      "source": [
        "trainDF.groupBy(\"Age\", \"Gender\").count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+------+\n",
            "|  Age|Gender| count|\n",
            "+-----+------+------+\n",
            "|51-55|     F|  6962|\n",
            "|18-25|     M| 52744|\n",
            "| 0-17|     F|  3548|\n",
            "|46-50|     M| 22722|\n",
            "|18-25|     F| 17192|\n",
            "|  55+|     M| 11541|\n",
            "|  55+|     F|  3583|\n",
            "|36-45|     M| 57967|\n",
            "|26-35|     F| 35670|\n",
            "| 0-17|     M|  7027|\n",
            "|36-45|     F| 19017|\n",
            "|51-55|     M| 20053|\n",
            "|26-35|     M|118248|\n",
            "|46-50|     F|  9191|\n",
            "+-----+------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgMCrJOYCxV3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8de3438c-614d-4141-88fc-6ebac1765d97"
      },
      "source": [
        "trainDF.select(\"Age\",\"Gender\",\"Purchase\").groupBy(\"Age\",\"Gender\").sum(\"Purchase\").alias(\"Age Group Purchase\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+-------------+\n",
            "|  Age|Gender|sum(Purchase)|\n",
            "+-----+------+-------------+\n",
            "|51-55|     F|     62724479|\n",
            "|18-25|     M|    496745484|\n",
            "| 0-17|     F|     29605153|\n",
            "|46-50|     M|    213164876|\n",
            "|18-25|     F|    143115866|\n",
            "|  55+|     M|    108894726|\n",
            "|  55+|     F|     32342305|\n",
            "|36-45|     M|    548151866|\n",
            "|26-35|     F|    311812355|\n",
            "| 0-17|     M|     64693751|\n",
            "|36-45|     F|    170230590|\n",
            "|51-55|     M|    194432303|\n",
            "|26-35|     M|   1109729324|\n",
            "|46-50|     F|     81011714|\n",
            "+-----+------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcZuCCP1CxWJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "db08c23f-80e2-4035-e87e-7265b245b805"
      },
      "source": [
        "trainDF.select(\"Age\",\"Gender\",\"Purchase\").groupBy(\"Age\",\"Gender\").agg(sum(\"Purchase\").alias(\"Age Group Purchase\"), avg(\"Purchase\").alias(\"Mean Age Group Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+------------------+-----------------------+\n",
            "|  Age|Gender|Age Group Purchase|Mean Age Group Purchase|\n",
            "+-----+------+------------------+-----------------------+\n",
            "|51-55|     F|          62724479|      9009.548836541224|\n",
            "|18-25|     M|         496745484|      9418.047247080236|\n",
            "| 0-17|     F|          29605153|      8344.180665163472|\n",
            "|46-50|     M|         213164876|      9381.431036000353|\n",
            "|18-25|     F|         143115866|      8324.561772917636|\n",
            "|  55+|     M|         108894726|      9435.467117234208|\n",
            "|  55+|     F|          32342305|      9026.599218531956|\n",
            "|36-45|     M|         548151866|      9456.274535511584|\n",
            "|26-35|     F|         311812355|      8741.585506027473|\n",
            "| 0-17|     M|          64693751|      9206.453820976234|\n",
            "|36-45|     F|         170230590|      8951.495504022716|\n",
            "|51-55|     M|         194432303|      9695.920959457439|\n",
            "|26-35|     M|        1109729324|      9384.761890264528|\n",
            "|46-50|     F|          81011714|       8814.24371667936|\n",
            "+-----+------+------------------+-----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfs22keoCxWm"
      },
      "source": [
        "#### Grouping with Expressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JU0goBwGCxWq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a46d9c6d-4254-4730-a7c7-4288ab4e1718"
      },
      "source": [
        "trainDF.groupBy(\"Age\").agg(\n",
        "  count(\"Purchase\").alias(\"quan\"),\n",
        "  expr(\"count(Purchase)\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+---------------+\n",
            "|  Age|  quan|count(Purchase)|\n",
            "+-----+------+---------------+\n",
            "|18-25| 69936|          69936|\n",
            "|26-35|153918|         153918|\n",
            "| 0-17| 10575|          10575|\n",
            "|46-50| 31913|          31913|\n",
            "|51-55| 27015|          27015|\n",
            "|36-45| 76984|          76984|\n",
            "|  55+| 15124|          15124|\n",
            "+-----+------+---------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2901c-L5CxXG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "396638c5-eb34-4631-e488-d4ed53e94294"
      },
      "source": [
        "trainDF.groupBy(\"Age\").agg(expr(\"avg(Purchase)\"),expr(\"stddev_pop(Purchase)\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----------------+--------------------+\n",
            "|  Age|    avg(Purchase)|stddev_pop(Purchase)|\n",
            "+-----+-----------------+--------------------+\n",
            "|18-25|9149.241449325098|    5030.73260424529|\n",
            "|26-35|9235.707837939683|   5001.417464297852|\n",
            "| 0-17|8917.154042553191|   5108.509402410989|\n",
            "|46-50| 9218.08009275217|   4973.931293087956|\n",
            "|51-55|9519.036905422914|   5074.569101301074|\n",
            "|36-45|9331.581315598047|   5025.818032593724|\n",
            "|  55+|9338.602948955302|   5026.226769074877|\n",
            "+-----+-----------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "j6qfSR14CxXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e6cb6ad4-3180-4c12-bf41-4e8380ae7cb7"
      },
      "source": [
        "## To find the mean of each age group in train dataset - Average purchases in each age group\n",
        "trainDF.groupby('Age').agg({'Purchase': 'mean'}).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----------------+\n",
            "|  Age|    avg(Purchase)|\n",
            "+-----+-----------------+\n",
            "|18-25|9149.241449325098|\n",
            "|26-35|9235.707837939683|\n",
            "| 0-17|8917.154042553191|\n",
            "|46-50| 9218.08009275217|\n",
            "|51-55|9519.036905422914|\n",
            "|36-45|9331.581315598047|\n",
            "|  55+|9338.602948955302|\n",
            "+-----+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT3I7O0NCxXv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "278049d6-1533-4717-ff8a-c18a242bbbf6"
      },
      "source": [
        "trainDF.groupby('Age').agg({'Purchase': 'sum'}).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------------+\n",
            "|  Age|sum(Purchase)|\n",
            "+-----+-------------+\n",
            "|18-25|    639861350|\n",
            "|26-35|   1421541679|\n",
            "| 0-17|     94298904|\n",
            "|46-50|    294176590|\n",
            "|51-55|    257156782|\n",
            "|36-45|    718382456|\n",
            "|  55+|    141237031|\n",
            "+-----+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "y95rjstECxX6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8b0d6bb9-78f8-4983-93bb-d883c0c416db"
      },
      "source": [
        "## Apply sum, min, max, count with groupby to get different summary insight for each group. \n",
        "exprs = {x: \"sum\" for x in trainDF.columns}\n",
        "trainDF.groupBy(\"Age\").agg(exprs).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------------------+-----------------------+-------------------+-------------+----------------+---------------+-------------------------------+-----------------------+--------+-----------+-----------------------+---------------+\n",
            "|  Age|sum(City_Category)|sum(Product_Category_3)|sum(Marital_Status)|sum(Purchase)|    sum(User_ID)|sum(Occupation)|sum(Stay_In_Current_City_Years)|sum(Product_Category_1)|sum(Age)|sum(Gender)|sum(Product_Category_2)|sum(Product_ID)|\n",
            "+-----+------------------+-----------------------+-------------------+-------------+----------------+---------------+-------------------------------+-----------------------+--------+-----------+-----------------------+---------------+\n",
            "|18-25|              null|               271580.0|            14766.0|    639861350| 7.0132128001E10|       471577.0|                        81943.0|               357761.0|    null|       null|               459321.0|           null|\n",
            "|26-35|              null|               592171.0|            60567.0|   1421541679|1.54397060368E11|      1215449.0|                       193282.0|               818600.0|    null|       null|              1035321.0|           null|\n",
            "| 0-17|              null|                40615.0|                0.0|     94298904| 1.0603748031E10|        92620.0|                        14302.0|                53926.0|    null|       null|                67544.0|           null|\n",
            "|46-50|              null|               121904.0|            23037.0|    294176590| 3.2014981722E10|       271471.0|                        36142.0|               183249.0|    null|       null|               220038.0|           null|\n",
            "|51-55|              null|               103419.0|            19378.0|    257156782| 2.7095772638E10|       238234.0|                        31051.0|               155666.0|    null|       null|               188292.0|           null|\n",
            "+-----+------------------+-----------------------+-------------------+-------------+----------------+---------------+-------------------------------+-----------------------+--------+-----------+-----------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyuIbc60CxYM"
      },
      "source": [
        "### 16. User-Defined Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vLcyCXyCxYP"
      },
      "source": [
        "##### a. simple UDF function for finding the cube of a number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CwPLxjYCxYT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1eed2646-5d86-4e83-e20a-297117b41bed"
      },
      "source": [
        "udfExampleDF = spark.range(5).toDF(\"num\")\n",
        "\n",
        "def power3(double_value):\n",
        "    return double_value ** 3\n",
        "\n",
        "power3(2.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPn8KCQhCxYi"
      },
      "source": [
        "Once the function is created, we need to register them with Spark so that we can used\n",
        "them on all of our worker machines. Spark will serialize the function on the driver, and transfer it over the network to all executor processes. This happens regardless of language.\n",
        "\n",
        "<br>Once we go to use the function, there are essentially two different things that occur. If the function is written in Scala or Java then we can use that function within the JVM. This means there will be little performance penalty aside from the fact that we can’t take advantage of code generation capabilities that Spark has for built-in functions.\n",
        "\n",
        "<br>If the function is written in Python, something quite different happens. \n",
        "Spark will start up a python process on the worker, serialize all of the data to a format that python can understand (remember it was in the JVM before), execute the function row by row on that data in the python process, before finally returning the results of the row operations to the JVM and Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PNyo2mkCxYn"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "power3udf = udf(power3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKr73RWrCxZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "869f0d18-2efc-4f2c-beeb-a6470384ebb5"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "udfExampleDF.select(power3udf(col(\"num\"))).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|power3(num)|\n",
            "+-----------+\n",
            "|          0|\n",
            "|          1|\n",
            "|          8|\n",
            "|         27|\n",
            "|         64|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ9yu_E4CxZT"
      },
      "source": [
        "##### b. Binning of Purchase column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB8DuhEMCxZY"
      },
      "source": [
        "def binning_purchase(purchase):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        Accepts Purchase amount and returns the correspondin bin\n",
        "    return:\n",
        "        bin number (Bin01,02,....) type=String\n",
        "    0       - 500       -> Bin01\n",
        "    501     - 1000      -> Bin02\n",
        "    1001    - 2000      -> Bin03\n",
        "    2001    - 4000      -> Bin04\n",
        "    4001    - 6000      -> Bin05\n",
        "    6001    - 8000      -> Bin06\n",
        "    8001    - 10000     -> Bin07\n",
        "    10001   - 20000     -> Bin08\n",
        "    20001   - 30000     -> Bin09\n",
        "    \"\"\"\n",
        "    if float(purchase) > 0:\n",
        "        purchase = float(purchase)\n",
        "    else:\n",
        "        purchase = float(0)\n",
        "    \n",
        "    if purchase <= 500: return str(\"Bin01\")\n",
        "    elif (purchase > 500 and purchase <= 1000): return str(\"Bin02\")\n",
        "    elif (purchase > 1000 and purchase <= 2000): return str(\"Bin03\")\n",
        "    elif (purchase > 2000 and purchase <= 4000): return str(\"Bin04\")\n",
        "    elif (purchase > 4000 and purchase <= 6000): return str(\"Bin05\")\n",
        "    elif (purchase > 6000 and purchase <= 8000): return str(\"Bin06\")\n",
        "    elif (purchase > 8000 and purchase <= 10000): return str(\"Bin07\")\n",
        "    elif (purchase > 10000 and purchase <= 20000): return str(\"Bin08\")\n",
        "    else:\n",
        "        return str(\"Bin09\")\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0jn_rU4CxZk"
      },
      "source": [
        "bin_purchase_udf = udf(binning_purchase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvluSA0PCxZt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f9d833e7-eda3-4c12-d359-4d70676c15fc"
      },
      "source": [
        "trainDF.withColumn('Binned_Purchase',bin_purchase_udf('Purchase')).select(\"Purchase\",\"Binned_Purchase\").show(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------+\n",
            "|Purchase|Binned_Purchase|\n",
            "+--------+---------------+\n",
            "|    2849|          Bin04|\n",
            "|   16622|          Bin08|\n",
            "|    8370|          Bin07|\n",
            "|    1057|          Bin03|\n",
            "+--------+---------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxQ2P_jDCxZ3"
      },
      "source": [
        "## 17. Joins\n",
        "\n",
        "#### Dataset\n",
        "* The data is obtained from Surfeous,a recommender system prototype that uses social annotations (e.g., tags) and contextual models to find restaurants that best suit the user preferences.It is a publicly available dataset in UCI.It has threee tables restaurants,consumers and user rating.The tables we choose are from them which are fitered for our scenario\n",
        "\n",
        "\n",
        "#### Data dictionary :\n",
        "* __RestGenInfo.csv__ contains :\n",
        "    * placeID - Uniqued Id of restaurants\n",
        "    * latitude - Location detail \n",
        "    * longitude - Location detail\n",
        "    * name - Name of the restaurant\n",
        "    * state - Name of the state \n",
        "    * alcohol - Constraints on having alcoholic beverages\n",
        "    * smoking_area - Information for smokers\n",
        "    * price - Pricing type of restaurant\n",
        "    * franchise - Does the restaurant have frachise\n",
        "    * area - open or close type of restaurant\n",
        "\n",
        "* __Cuisine.csv__ contains :\n",
        "    * placeID - Uniqued Id of restaurants\n",
        "    * Rcuisine - Different styles of food\n",
        "\n",
        "    \n",
        "* __PaymentMode.csv__ contains :\n",
        "    * placeID - Uniqued Id of restaurants\n",
        "    * Rpayment - Different modes of payment\n",
        "\n",
        "    \n",
        "* __parking.csv__ contains :\n",
        "     * placeID - Uniqued Id of restaurants\n",
        "     * parking_lot - Different types of parking available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdiSfp0hCxZ7"
      },
      "source": [
        "#### Read the data as a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4xnCyLzCxaA"
      },
      "source": [
        "restoGen = spark.read.csv('drive/My Drive/google_cloud/data/RestaurantsData/RestGenInfo.csv', header=True, inferSchema=True,nullValue='?')\n",
        "cuisine = spark.read.csv('drive/My Drive/google_cloud/data/RestaurantsData/Cuisine.csv', header=True, inferSchema=True)\n",
        "paymentMode = spark.read.csv('drive/My Drive/google_cloud/data/RestaurantsData/PaymentMode.csv', header=True, inferSchema=True)\n",
        "parking = spark.read.csv('drive/My Drive/google_cloud/data/RestaurantsData/parking.csv', header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkbYk6lJCxaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "6c8fd02a-3b00-4878-b264-32b8dd928040"
      },
      "source": [
        "restoGen.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------------+--------------------+----------+-----------------+-------------+------+---------+------+\n",
            "|placeID|  latitude|   longitude|                name|     state|          alcohol| smoking_area| price|franchise|  area|\n",
            "+-------+----------+------------+--------------------+----------+-----------------+-------------+------+---------+------+\n",
            "| 132560|23.7523041| -99.1669133|  puesto de gorditas|Tamaulipas|No_Alcohol_Served|    permitted|   low|        f|  open|\n",
            "| 132561| 23.726819| -99.1265059|          cafe ambar|      null|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132564|23.7309245| -99.1451848|             churchs|      null|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132572|22.1416471|-100.9927118|        Cafe Chaires|       SLP|No_Alcohol_Served|not permitted|   low|        f|closed|\n",
            "| 132583|18.9222904|  -99.234332|    McDonalds Centro|   Morelos|No_Alcohol_Served|not permitted|   low|        t|closed|\n",
            "| 132584|23.7523648| -99.1652879|  Gorditas Dona Tota|      null|No_Alcohol_Served|not permitted|medium|        t|closed|\n",
            "| 132594|23.7521677|  -99.165709|tacos de barbacoa...|      null|No_Alcohol_Served|not permitted|   low|        f|  open|\n",
            "| 132608|23.7588052| -99.1651297|Hamburguesas La p...|Tamaulipas|No_Alcohol_Served|    permitted|   low|        t|  open|\n",
            "| 132609|23.7602683| -99.1658646|Pollo_Frito_Bueno...|Tamaulipas|No_Alcohol_Served|not permitted|   low|        t|closed|\n",
            "| 132613|23.7529035|  -99.165076|       carnitas_mata|Tamaulipas|No_Alcohol_Served|    permitted|medium|        t|closed|\n",
            "| 132626|23.7375834| -99.1351318|la perica hamburg...|Tamaulipas|No_Alcohol_Served|         none|medium|        t|closed|\n",
            "| 132630|23.7529305| -99.1644725|          palomo tec|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132654|23.7355234| -99.1295877|Carnitas Mata  Ca...|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132660|23.7529428| -99.1646791|carnitas mata cal...|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132663|23.7525107| -99.1669536|           tacos abi|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132665|23.7367977| -99.1342413|  TACOS CORRECAMINOS|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132667|23.7526973| -99.1633594|little pizza Emil...|Tamaulipas|No_Alcohol_Served|         none|   low|        t|closed|\n",
            "| 132668| 23.738212| -99.1519547|      TACOS EL GUERO|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132706|23.7292162| -99.1323571|  Gorditas Dona Tota|Tamaulipas|No_Alcohol_Served|not permitted|medium|        t|closed|\n",
            "| 132715|23.7324226| -99.1586602|tacos de la estacion|      null|No_Alcohol_Served|         none|   low|        f|  open|\n",
            "+-------+----------+------------+--------------------+----------+-----------------+-------------+------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGx_WzguCxaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e2d1781-db37-44e9-cf5a-0e3eeae7ff06"
      },
      "source": [
        "restoGen.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nbTzaqzCxat",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b3a980f-06b9-4635-b1c6-5378652fddf9"
      },
      "source": [
        "restoGen.select('PlaceID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuEwHyFZCxa-"
      },
      "source": [
        "#### Check for any null values in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffu2s42xCxbB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "09633d27-78a2-4880-96b9-cb9d56a86f47"
      },
      "source": [
        "restoGen.select([count(when(isnan(c)| col(c).isNull(), 1)).alias(c) for c in restoGen.columns]).show()\n",
        "cuisine.select([count(when(isnan(c)| col(c).isNull(), 1)).alias(c) for c in cuisine.columns]).show()\n",
        "paymentMode.select([count(when(isnan(c)| col(c).isNull(), 1)).alias(c) for c in paymentMode.columns]).show()\n",
        "parking.select([count(when(isnan(c)| col(c).isNull(), 1)).alias(c) for c in parking.columns]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------+---------+----+-----+-------+------------+-----+---------+----+\n",
            "|placeID|latitude|longitude|name|state|alcohol|smoking_area|price|franchise|area|\n",
            "+-------+--------+---------+----+-----+-------+------------+-----+---------+----+\n",
            "|      0|       0|        0|   0|   18|      0|           0|    0|        0|   0|\n",
            "+-------+--------+---------+----+-----+-------+------------+-----+---------+----+\n",
            "\n",
            "+-------+--------+\n",
            "|placeID|Rcuisine|\n",
            "+-------+--------+\n",
            "|      0|       0|\n",
            "+-------+--------+\n",
            "\n",
            "+-------+--------+\n",
            "|placeID|Rpayment|\n",
            "+-------+--------+\n",
            "|      0|       0|\n",
            "+-------+--------+\n",
            "\n",
            "+-------+-----------+\n",
            "|placeID|parking_lot|\n",
            "+-------+-----------+\n",
            "|      0|          0|\n",
            "+-------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoNWp_8OCxbS"
      },
      "source": [
        "restoGen = restoGen.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqg_YbgOCxbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cf25ef0-13f1-47c3-ebad-e5048f90814f"
      },
      "source": [
        "restoGen.select('placeID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZDCE4hECxbo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9a60781-b8f3-46b9-afab-18a74bf0773b"
      },
      "source": [
        "cuisine.select('placeID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3tV8E8yCxbw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5892f02-4545-41ec-c462-17621b07795a"
      },
      "source": [
        "paymentMode.select('placeID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTUdl7Z9Cxb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98318a6d-e9aa-431d-84d7-2a07609066ef"
      },
      "source": [
        "parking.select('placeID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "675"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsb0ZPkzCxcA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29e26c85-a382-4f6a-914c-b36d138bc6ed"
      },
      "source": [
        "cuisine.select('Rcuisine').distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtYgJ7PZCxcJ"
      },
      "source": [
        "restoGen.createOrReplaceTempView('restoGenTable')\n",
        "cuisine.createOrReplaceTempView('cuisineTable')\n",
        "paymentMode.createOrReplaceTempView('paymentModeTable')\n",
        "parking.createOrReplaceTempView('parkingTable')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CMXhRcXCxcY"
      },
      "source": [
        " ## The  count of restaurants(as numberOfHotels) for each payment modes and area. Also order them based on numberOfHotels in descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdGNU5BBCxcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ff3d31b6-ecd4-434c-a490-3bed62227c55"
      },
      "source": [
        "spark.sql('''select  count(*) as numberOfHotels, Rpayment, area from\n",
        "restoGenTable a join paymentModeTable b \n",
        "where a.placeID = b.placeID group by Rpayment, area \n",
        "order by numberOfHotels desc''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-------------------+------+\n",
            "|numberOfHotels|           Rpayment|  area|\n",
            "+--------------+-------------------+------+\n",
            "|            92|               cash|closed|\n",
            "|            44|               VISA|closed|\n",
            "|            40|MasterCard-Eurocard|closed|\n",
            "|            24|   American_Express|closed|\n",
            "|            11|               cash|  open|\n",
            "|            11|   bank_debit_cards|closed|\n",
            "|             3|               VISA|  open|\n",
            "|             2|MasterCard-Eurocard|  open|\n",
            "|             1|   bank_debit_cards|  open|\n",
            "|             1|   American_Express|  open|\n",
            "|             1|      Carte_Blanche|closed|\n",
            "+--------------+-------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7gNW7vICxcl"
      },
      "source": [
        "#### Inner Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyfzm32pCxcp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "1d38f35c-5f06-482b-e229-3d8275b94e1d"
      },
      "source": [
        "inner_join = restoGen.join(paymentMode, restoGen.placeID == paymentMode.placeID,how='inner') \n",
        "inner_join.show(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------------+--------------------+-------+-----------------+-------------+------+---------+------+-------+-------------------+\n",
            "|placeID|  latitude|   longitude|                name|  state|          alcohol| smoking_area| price|franchise|  area|placeID|           Rpayment|\n",
            "+-------+----------+------------+--------------------+-------+-----------------+-------------+------+---------+------+-------+-------------------+\n",
            "| 135106|22.1497088|-100.9760928|El Rinc�n de San ...|    SLP|        Wine-Beer|  only at bar|medium|        f|  open| 135106|               cash|\n",
            "| 135106|22.1497088|-100.9760928|El Rinc�n de San ...|    SLP|        Wine-Beer|  only at bar|medium|        f|  open| 135106|               VISA|\n",
            "| 135106|22.1497088|-100.9760928|El Rinc�n de San ...|    SLP|        Wine-Beer|  only at bar|medium|        f|  open| 135106|MasterCard-Eurocard|\n",
            "| 135088|18.8760113| -99.2198896|   Cafeteria cenidet|Morelos|No_Alcohol_Served|not permitted|   low|        f|closed| 135088|               cash|\n",
            "+-------+----------+------------+--------------------+-------+-----------------+-------------+------+---------+------+-------+-------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE0hX7loCxc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "9dd1e09b-6c04-4786-a7d3-2aac274802a5"
      },
      "source": [
        "count_of_hotels = inner_join.select('Rpayment','area').groupby('area','Rpayment').count()\n",
        "\n",
        "count_of_hotels = count_of_hotels.withColumnRenamed('count','NumberofHotels')\n",
        "count_of_hotels.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------------+--------------+\n",
            "|  area|           Rpayment|NumberofHotels|\n",
            "+------+-------------------+--------------+\n",
            "|  open|   American_Express|             1|\n",
            "|  open|   bank_debit_cards|             1|\n",
            "|closed|   bank_debit_cards|            11|\n",
            "|  open|               cash|            11|\n",
            "|closed|   American_Express|            24|\n",
            "|closed|               VISA|            44|\n",
            "|closed|      Carte_Blanche|             1|\n",
            "|  open|               VISA|             3|\n",
            "|closed|               cash|            92|\n",
            "|closed|MasterCard-Eurocard|            40|\n",
            "|  open|MasterCard-Eurocard|             2|\n",
            "+------+-------------------+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5_GX9Sl_CxdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f74f73f2-7a76-4656-db58-b5c9bf2ed7af"
      },
      "source": [
        "count_of_hotels.orderBy(count_of_hotels.NumberofHotels.desc()).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------------+--------------+\n",
            "|  area|           Rpayment|NumberofHotels|\n",
            "+------+-------------------+--------------+\n",
            "|closed|               cash|            92|\n",
            "|closed|               VISA|            44|\n",
            "|closed|MasterCard-Eurocard|            40|\n",
            "|closed|   American_Express|            24|\n",
            "|closed|   bank_debit_cards|            11|\n",
            "|  open|               cash|            11|\n",
            "|  open|               VISA|             3|\n",
            "|  open|MasterCard-Eurocard|             2|\n",
            "|  open|   American_Express|             1|\n",
            "|  open|   bank_debit_cards|             1|\n",
            "|closed|      Carte_Blanche|             1|\n",
            "+------+-------------------+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuU99hXUCxde"
      },
      "source": [
        "##  Count the number of Cuisines that are used by the Restaurants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DBKt8Q-Cxdh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "e0d9474d-bff4-4352-a279-59d0aad19a55"
      },
      "source": [
        "print(\"The number of Disintct Cuisines Available from all the restaurants = \",cuisine.select('Rcuisine').distinct().count())\n",
        "left_join = restoGen.join(cuisine, on=restoGen.placeID==cuisine.placeID, how = 'left').drop(cuisine.placeID)\n",
        "print(\"The number of cusines used in the selected Restaurants: \")\n",
        "left_join.select(countDistinct('Rcuisine').alias(\" Distinct Cusines  used in Restaurants\")).show()\n",
        "print(\"The Cusinies available are \")\n",
        "left_join.select('Rcuisine').distinct().alias(\"Cusines  used in Restaurants\").show(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('The number of Disintct Cuisines Available from all the restaurants = ', 59)\n",
            "The number of cusines used in the selected Restaurants: \n",
            "+--------------------------------------+\n",
            "| Distinct Cusines  used in Restaurants|\n",
            "+--------------------------------------+\n",
            "|                                    22|\n",
            "+--------------------------------------+\n",
            "\n",
            "The Cusinies available are \n",
            "+----------------+\n",
            "|        Rcuisine|\n",
            "+----------------+\n",
            "|   International|\n",
            "|       Cafeteria|\n",
            "|         Mexican|\n",
            "|          Bakery|\n",
            "|             Bar|\n",
            "|        Armenian|\n",
            "|         Chinese|\n",
            "|            null|\n",
            "|       Fast_Food|\n",
            "|        Japanese|\n",
            "|          Family|\n",
            "|      Vietnamese|\n",
            "|         Burgers|\n",
            "|Breakfast-Brunch|\n",
            "|         Italian|\n",
            "|        Pizzeria|\n",
            "|            Game|\n",
            "|         Seafood|\n",
            "|        Regional|\n",
            "| Bar_Pub_Brewery|\n",
            "|Cafe-Coffee_Shop|\n",
            "|        American|\n",
            "|    Contemporary|\n",
            "+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvkaVVRJCxdq"
      },
      "source": [
        "## Count the distinct restaurant names which has valet parking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAQbiFqUCxdt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2f211c05-4a6d-47c9-a841-bf2dd1301c9c"
      },
      "source": [
        "spark.sql('''select distinct name ,parking_lot from restoGenTable a join parkingTable b where a.placeID = b.placeID and \n",
        "          b.parking_lot = 'valet parking' ''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+\n",
            "|                name|  parking_lot|\n",
            "+--------------------+-------------+\n",
            "|La Posada del Virrey|valet parking|\n",
            "+--------------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mEtsb7DCxd5"
      },
      "source": [
        "#### Right Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLXHrQSlCxd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b90c7840-8b84-4f9c-bd2f-8427110bf9fd"
      },
      "source": [
        "right_join = restoGen.join(other=parking,on=parking.placeID==restoGen.placeID,how='right')\n",
        "names_of_restaurants = right_join.select('name','parking_lot').filter(parking.parking_lot=='valet parking')\n",
        "names_of_restaurants.distinct().filter(names_of_restaurants.name!='null').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------------+\n",
            "|                name|  parking_lot|\n",
            "+--------------------+-------------+\n",
            "|La Posada del Virrey|valet parking|\n",
            "+--------------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJhQYeA2CxeH"
      },
      "source": [
        "## Identify the placeID where the paymentMode for parking  is not available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muI_i15TCxeK"
      },
      "source": [
        "#### Full outer Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pInh-jF0CxeM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af2e5a43-9610-4d58-c2d4-81f335da18cd"
      },
      "source": [
        "spark.sql(\"\"\"SELECT parkingTable.placeID,parkingTable.parking_lot,paymentModeTable.Rpayment\n",
        "FROM parkingTable\n",
        "FULL OUTER JOIN paymentModeTable ON parkingTable.placeID=paymentModeTable.placeID WHERE paymentModeTable.Rpayment is NULL\"\"\").show(1000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+--------+\n",
            "|placeID|parking_lot|Rpayment|\n",
            "+-------+-----------+--------+\n",
            "| 133018|       none|    null|\n",
            "| 132478|       none|    null|\n",
            "| 132478|        fee|    null|\n",
            "| 132663|       none|    null|\n",
            "| 135108|       none|    null|\n",
            "| 134979|       none|    null|\n",
            "| 133010|        yes|    null|\n",
            "| 132479|     street|    null|\n",
            "| 132831|       none|    null|\n",
            "| 132292|     public|    null|\n",
            "| 132292|     street|    null|\n",
            "| 133012|       none|    null|\n",
            "| 132661|       none|    null|\n",
            "| 132484|        yes|    null|\n",
            "| 132326|        yes|    null|\n",
            "| 132326|     public|    null|\n",
            "| 132881|       none|    null|\n",
            "| 135019|       none|    null|\n",
            "| 132999|       none|    null|\n",
            "| 132568|       none|    null|\n",
            "| 132643|       none|    null|\n",
            "| 135026|       none|    null|\n",
            "| 132876|       none|    null|\n",
            "| 132882|       none|    null|\n",
            "| 132570|       none|    null|\n",
            "| 132816|       none|    null|\n",
            "| 133041|       none|    null|\n",
            "| 132639|       none|    null|\n",
            "| 133039|       none|    null|\n",
            "| 132656|       none|    null|\n",
            "| 132839|       none|    null|\n",
            "| 134986|        yes|    null|\n",
            "| 132830|       none|    null|\n",
            "| 133013|       none|    null|\n",
            "| 132646|       none|    null|\n",
            "| 132878|       none|    null|\n",
            "| 133015|       none|    null|\n",
            "| 133003|       none|    null|\n",
            "| 132630|       none|    null|\n",
            "| 132571|       none|    null|\n",
            "| 132647|       none|    null|\n",
            "| 133006|       none|    null|\n",
            "| 132664|       none|    null|\n",
            "| 132557|     public|    null|\n",
            "| 132557|     street|    null|\n",
            "| 132652|       none|    null|\n",
            "| 132832|       none|    null|\n",
            "| 133005|       none|    null|\n",
            "| 132823|       none|    null|\n",
            "| 132377|     street|    null|\n",
            "| 132666|       none|    null|\n",
            "| 132833|       none|    null|\n",
            "| 132641|       none|    null|\n",
            "| 132838|       none|    null|\n",
            "| 132657|       none|    null|\n",
            "| 132468|       none|    null|\n",
            "| 132491|     public|    null|\n",
            "| 132491|     street|    null|\n",
            "| 132879|       none|    null|\n",
            "| 132649|       none|    null|\n",
            "| 133022|       none|    null|\n",
            "| 132632|       none|    null|\n",
            "| 132634|       none|    null|\n",
            "| 132673|       none|    null|\n",
            "| 133000|       none|    null|\n",
            "| 133023|       none|    null|\n",
            "| 132812|       none|    null|\n",
            "| 133019|       none|    null|\n",
            "| 132281|     public|    null|\n",
            "| 132281|     street|    null|\n",
            "| 132561|       none|    null|\n",
            "| 132562|       none|    null|\n",
            "| 132644|       none|    null|\n",
            "| 132844|       none|    null|\n",
            "| 132157|        yes|    null|\n",
            "| 132487|        yes|    null|\n",
            "| 133011|       none|    null|\n",
            "| 133042|       none|    null|\n",
            "| 132670|       none|    null|\n",
            "| 132877|       none|    null|\n",
            "| 132669|       none|    null|\n",
            "| 132906|       none|    null|\n",
            "| 133017|       none|    null|\n",
            "| 132564|       none|    null|\n",
            "| 132672|       none|    null|\n",
            "| 133004|       none|    null|\n",
            "| 132633|       none|    null|\n",
            "| 134997|       none|    null|\n",
            "| 132813|       none|    null|\n",
            "| 132662|       none|    null|\n",
            "| 132729|       none|    null|\n",
            "| 132579|       none|    null|\n",
            "| 133021|       none|    null|\n",
            "| 135020|        yes|    null|\n",
            "| 133025|       none|    null|\n",
            "| 132654|       none|    null|\n",
            "| 132998|       none|    null|\n",
            "| 132883|       none|    null|\n",
            "| 135111|     public|    null|\n",
            "| 132822|       none|    null|\n",
            "| 132874|       none|    null|\n",
            "| 132566|       none|    null|\n",
            "| 132569|       none|    null|\n",
            "| 132997|     public|    null|\n",
            "| 132659|       none|    null|\n",
            "| 132668|       none|    null|\n",
            "| 132884|       none|    null|\n",
            "| 132943|     public|    null|\n",
            "| 133040|       none|    null|\n",
            "| 132567|       none|    null|\n",
            "| 132992|       none|    null|\n",
            "| 132481|        fee|    null|\n",
            "| 132481|     street|    null|\n",
            "| 133016|       none|    null|\n",
            "| 132660|       none|    null|\n",
            "| 132563|       none|    null|\n",
            "| 133024|       none|    null|\n",
            "| 132898|       none|    null|\n",
            "| 132665|       none|    null|\n",
            "| 132905|       none|    null|\n",
            "| 133001|       none|    null|\n",
            "| 132651|       none|    null|\n",
            "| 132818|        fee|    null|\n",
            "| 132637|       none|    null|\n",
            "| 133002|       none|    null|\n",
            "| 132565|       none|    null|\n",
            "+-------+-----------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nu75B81CxeU"
      },
      "source": [
        "## The restaurant names and their corresponding restaurant cuisine styles, price, location details(latitude, longitude) and smoking_area informations only for those which are located in Morelos state and have closed roofing, also order based on price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWXOJ7_wCxeW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "06a8bb10-d42e-4ef3-db89-599f1834b3bf"
      },
      "source": [
        "spark.sql('''select distinct name, Rcuisine, price, latitude, longitude, smoking_area from \n",
        "restoGenTable a join cuisineTable b \n",
        "where a.placeID = b.placeID and a.state = 'Morelos' and a.area = 'closed' \n",
        "order by price''').show(truncate = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------+---------------+------+----------+-----------+-------------+\n",
            "|name                                                |Rcuisine       |price |latitude  |longitude  |smoking_area |\n",
            "+----------------------------------------------------+---------------+------+----------+-----------+-------------+\n",
            "|Restaurant and Bar and Clothesline Carlos N Charlies|Bar            |high  |18.948657 |-99.235361 |section      |\n",
            "|Restaurant and Bar and Clothesline Carlos N Charlies|Bar_Pub_Brewery|high  |18.948657 |-99.235361 |section      |\n",
            "|Restaurant Las Mananitas                            |International  |high  |18.928798 |-99.239513 |none         |\n",
            "|Cafeteria cenidet                                   |Cafeteria      |low   |18.8760113|-99.2198896|not permitted|\n",
            "|Restaurant Bar Coty y Pablo                         |Bar            |low   |18.875011 |-99.159422 |none         |\n",
            "|Subway                                              |Fast_Food      |low   |18.933537 |-99.222497 |not permitted|\n",
            "|McDonalds Centro                                    |American       |low   |18.9222904|-99.234332 |not permitted|\n",
            "|Kiku Cuernavaca                                     |Japanese       |medium|18.915421 |-99.184871 |none         |\n",
            "|Mariscos Tia Licha                                  |Family         |medium|18.9257734|-99.2326355|not permitted|\n",
            "|Mikasa                                              |Japanese       |medium|18.9101777|-99.2315438|none         |\n",
            "+----------------------------------------------------+---------------+------+----------+-----------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyahwFAiCxee"
      },
      "source": [
        "#### Natural Joins\n",
        "Natural joins make implicit guesses at the columns on which you would like to join. \n",
        "It finds matching columns and returns the results. \n",
        "Left, right, and outer natural joins are all supported.\n",
        "\n",
        "WARNING:\n",
        "Implicit is always dangerous! \n",
        "The following query will give us incorrect results because \n",
        "the two DataFrames/tables share a column name (id), but it means different things in the datasets. \n",
        "You should always use this join with caution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0oF2fk6mCxeh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "71ea2ea2-b08a-4dfd-a58f-f75d5d140f37"
      },
      "source": [
        "#spark.sql(\"\"\"SELECT * FROM TableA NATURAL JOIN TableB\"\"\").show()\n",
        "\n",
        "spark.sql('''select  * from restoGenTable a NATURAL JOIN paymentModeTable b ''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------------+--------------------+-------+-----------------+-------------+------+---------+------+-------------------+\n",
            "|placeID|  latitude|   longitude|                name|  state|          alcohol| smoking_area| price|franchise|  area|           Rpayment|\n",
            "+-------+----------+------------+--------------------+-------+-----------------+-------------+------+---------+------+-------------------+\n",
            "| 135106|22.1497088|-100.9760928|El Rinc�n de San ...|    SLP|        Wine-Beer|  only at bar|medium|        f|  open|               cash|\n",
            "| 135106|22.1497088|-100.9760928|El Rinc�n de San ...|    SLP|        Wine-Beer|  only at bar|medium|        f|  open|               VISA|\n",
            "| 135106|22.1497088|-100.9760928|El Rinc�n de San ...|    SLP|        Wine-Beer|  only at bar|medium|        f|  open|MasterCard-Eurocard|\n",
            "| 135088|18.8760113| -99.2198896|   Cafeteria cenidet|Morelos|No_Alcohol_Served|not permitted|   low|        f|closed|               cash|\n",
            "| 135086| 22.141421| -101.013955|Mcdonalds Parque ...|    SLP|No_Alcohol_Served|not permitted|medium|        t|closed|               cash|\n",
            "| 135086| 22.141421| -101.013955|Mcdonalds Parque ...|    SLP|No_Alcohol_Served|not permitted|medium|        t|closed|               VISA|\n",
            "| 135086| 22.141421| -101.013955|Mcdonalds Parque ...|    SLP|No_Alcohol_Served|not permitted|medium|        t|closed|MasterCard-Eurocard|\n",
            "| 135085| 22.150802|  -100.98268|Tortas Locas Hipo...|    SLP|No_Alcohol_Served|not permitted|medium|        f|closed|               cash|\n",
            "| 135082| 22.151448| -100.915099|la Estrella de Dimas|    SLP|No_Alcohol_Served|         none|medium|        f|closed|               cash|\n",
            "| 135081| 22.164842| -100.960493|             El Club|    SLP|No_Alcohol_Served|         none|medium|        f|closed|               cash|\n",
            "| 135081| 22.164842| -100.960493|             El Club|    SLP|No_Alcohol_Served|         none|medium|        f|closed|               VISA|\n",
            "| 135081| 22.164842| -100.960493|             El Club|    SLP|No_Alcohol_Served|         none|medium|        f|closed|MasterCard-Eurocard|\n",
            "| 135080| 22.145008| -100.997969|         los Toneles|    SLP|No_Alcohol_Served|      section|  high|        f|closed|               cash|\n",
            "| 135080| 22.145008| -100.997969|         los Toneles|    SLP|No_Alcohol_Served|      section|  high|        f|closed|               VISA|\n",
            "| 135080| 22.145008| -100.997969|         los Toneles|    SLP|No_Alcohol_Served|      section|  high|        f|closed|MasterCard-Eurocard|\n",
            "| 135080| 22.145008| -100.997969|         los Toneles|    SLP|No_Alcohol_Served|      section|  high|        f|closed|   American_Express|\n",
            "| 135079| 22.156376| -100.998355|          Koye Sushi|    SLP|No_Alcohol_Served|         none|  high|        f|closed|               cash|\n",
            "| 135079| 22.156376| -100.998355|          Koye Sushi|    SLP|No_Alcohol_Served|         none|  high|        f|closed|   American_Express|\n",
            "| 135076| 22.181017| -100.973614|Restaurante Puebl...|    SLP|        Wine-Beer|         none|  high|        f|closed|               cash|\n",
            "| 135076| 22.181017| -100.973614|Restaurante Puebl...|    SLP|        Wine-Beer|         none|  high|        f|closed|               VISA|\n",
            "+-------+----------+------------+--------------------+-------+-----------------+-------------+------+---------+------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJBE2Gv_Cxeo"
      },
      "source": [
        "#### Cross (Cartesian) Joins\n",
        "Cross-joins in simplest terms are inner joins that do not specify a predicate. \n",
        "Cross joins will join every single row in the left DataFrame to ever single row in the right DataFrame. \n",
        "This will cause an absolute explosion in the number of rows contained in the resulting DataFrame. \n",
        "If you have 1,000 rows in each DataFrame, the cross-join of these will result in 1,000,000 (1,000 x 1,000) rows. \n",
        "For this reason, you must very explicitly state that you want a cross-join by using the cross join keyword:"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "scrolled": true,
        "id": "XnoCcdksCxe6"
      },
      "source": [
        "tableA.crossJoin(tableB).show()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "scrolled": true,
        "id": "_hS7H3s8Cxe9"
      },
      "source": [
        "spark.sql(\"\"\"SELECT * FROM TableA CROSS JOIN TableB\"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwObksb8CxfA"
      },
      "source": [
        "#### Random Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1-34sUrCxfC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53e39dd9-a18f-458c-8280-177e96e5aeca"
      },
      "source": [
        "## To create a sample DataFrame from the base DataFrame\n",
        "## Use sample operation to take sample of a DataFrame. \n",
        "## The sample method on DataFrame will return a DataFrame containing the sample of base DataFrame. \n",
        "## The sample method takes 3 parameters.\n",
        "## withReplacement = True or False to select a observation with or without replacement.\n",
        "## fraction = x, where x = .5 shows that we want to have 50% data in sample DataFrame.\n",
        "## seed to reproduce the result\n",
        "sampleDF1 = trainDF.sample(False, 0.2, 1234)\n",
        "sampleDF2 = trainDF.sample(False, 0.2, 4321)\n",
        "print(sampleDF1.count(), sampleDF2.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76916, 76981)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU5Z5kS3CxfK"
      },
      "source": [
        "### Miscellaneous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziBv8PHnCxfN"
      },
      "source": [
        "#### Unions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYNdDGJcCxfP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "606c4393-5f00-47da-8745-ac2f8ff857ac"
      },
      "source": [
        "df1 = spark.createDataFrame([[1, 'Alex', 25],[3, 'Carol', 53],[5, 'Emily', 25],[7, 'Gabriel', 32],[9, 'Ilma', 35],[11, 'Kim', 45]], ['id', 'name', 'age'])\n",
        "df2 = spark.createDataFrame([[2, 'Ben', 66],[4, 'Daniel', 28],[6, 'Frank', 64],[8, 'Harley', 29],[10, 'Jack', 35],[12, 'Litmya', 45]], ['id', 'name', 'age'])\n",
        "print(\"Before\")\n",
        "print(\"DataFrame-1\")\n",
        "print(df1.show())\n",
        "print(\"DataFrame-2\")\n",
        "print(df2.show())\n",
        "print(\"After\")\n",
        "df1 = df1.union(df2)\n",
        "print(\"DataFrame-1\")\n",
        "print(df1.show())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before\n",
            "DataFrame-1\n",
            "+---+-------+---+\n",
            "| id|   name|age|\n",
            "+---+-------+---+\n",
            "|  1|   Alex| 25|\n",
            "|  3|  Carol| 53|\n",
            "|  5|  Emily| 25|\n",
            "|  7|Gabriel| 32|\n",
            "|  9|   Ilma| 35|\n",
            "| 11|    Kim| 45|\n",
            "+---+-------+---+\n",
            "\n",
            "None\n",
            "DataFrame-2\n",
            "+---+------+---+\n",
            "| id|  name|age|\n",
            "+---+------+---+\n",
            "|  2|   Ben| 66|\n",
            "|  4|Daniel| 28|\n",
            "|  6| Frank| 64|\n",
            "|  8|Harley| 29|\n",
            "| 10|  Jack| 35|\n",
            "| 12|Litmya| 45|\n",
            "+---+------+---+\n",
            "\n",
            "None\n",
            "After\n",
            "DataFrame-1\n",
            "+---+-------+---+\n",
            "| id|   name|age|\n",
            "+---+-------+---+\n",
            "|  1|   Alex| 25|\n",
            "|  3|  Carol| 53|\n",
            "|  5|  Emily| 25|\n",
            "|  7|Gabriel| 32|\n",
            "|  9|   Ilma| 35|\n",
            "| 11|    Kim| 45|\n",
            "|  2|    Ben| 66|\n",
            "|  4| Daniel| 28|\n",
            "|  6|  Frank| 64|\n",
            "|  8| Harley| 29|\n",
            "| 10|   Jack| 35|\n",
            "| 12| Litmya| 45|\n",
            "+---+-------+---+\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgm5zAXUCxfg"
      },
      "source": [
        "#### Unions and condtional append"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLvWbng7Cxfj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "a844cfc2-5ffd-44fa-9b46-e932c996338f"
      },
      "source": [
        "df1.union(df2).where(\"age < 60\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------+---+\n",
            "| id|   name|age|\n",
            "+---+-------+---+\n",
            "|  1|   Alex| 25|\n",
            "|  3|  Carol| 53|\n",
            "|  5|  Emily| 25|\n",
            "|  7|Gabriel| 32|\n",
            "|  9|   Ilma| 35|\n",
            "| 11|    Kim| 45|\n",
            "|  4| Daniel| 28|\n",
            "|  8| Harley| 29|\n",
            "| 10|   Jack| 35|\n",
            "| 12| Litmya| 45|\n",
            "|  4| Daniel| 28|\n",
            "|  8| Harley| 29|\n",
            "| 10|   Jack| 35|\n",
            "| 12| Litmya| 45|\n",
            "+---+-------+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGm5q-4_Cxf3"
      },
      "source": [
        "#### String Manipulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH3njUkyCxf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "685b7ad6-d08e-45e2-eed1-ebf655ca15cb"
      },
      "source": [
        "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim\n",
        "\n",
        "trainDF.select(\n",
        "ltrim(lit(\" HELLO \")).alias(\"ltrim\"),\n",
        "rtrim(lit(\" HELLO \")).alias(\"rtrim\"),\n",
        "trim(lit(\" HELLO \")).alias(\"trim\"),\n",
        "lpad(lit(\"HELLO\"), 7, \" \").alias(\"lp\"),\n",
        "rpad(lit(\"HELLO\"), 7, \" \").alias(\"rp\"))\\\n",
        ".show(2,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+------+-----+-------+-------+\n",
            "|ltrim |rtrim |trim |lp     |rp     |\n",
            "+------+------+-----+-------+-------+\n",
            "|HELLO | HELLO|HELLO|  HELLO|HELLO  |\n",
            "|HELLO | HELLO|HELLO|  HELLO|HELLO  |\n",
            "+------+------+-----+-------+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhnrZ1ceCxgH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ac90b904-443d-4c15-de7a-dc643943a18a"
      },
      "source": [
        "spark.sql(\"\"\"SELECT\n",
        "ltrim(' HELLLOOOO ') AS ltrim,\n",
        "rtrim(' HELLLOOOO ') AS rtrim,\n",
        "trim(' HELLLOOOO ') AS trim,\n",
        "lpad('HELLOOOO ', 3, ' ') AS lp,\n",
        "rpad('HELLOOOO ', 10, ' ') AS rp\n",
        "FROM\n",
        "trainDFTable\"\"\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----------+---------+---+----------+\n",
            "|     ltrim|     rtrim|     trim| lp|        rp|\n",
            "+----------+----------+---------+---+----------+\n",
            "|HELLLOOOO | HELLLOOOO|HELLLOOOO|HEL|HELLOOOO  |\n",
            "|HELLLOOOO | HELLLOOOO|HELLLOOOO|HEL|HELLOOOO  |\n",
            "+----------+----------+---------+---+----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNn414wKCxgP"
      },
      "source": [
        "#### Working with Date and Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wx1Blu7CxgR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c170eb71-2290-492b-918c-12076e2d453a"
      },
      "source": [
        "from pyspark.sql.functions import current_date, current_timestamp\n",
        "dateDF = spark.range(10)\\\n",
        ".withColumn(\"today\", current_date())\\\n",
        ".withColumn(\"now\", current_timestamp())\n",
        "dateDF.show(truncate = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----------+-----------------------+\n",
            "|id |today     |now                    |\n",
            "+---+----------+-----------------------+\n",
            "|0  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "|1  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "|2  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "|3  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "|4  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "|5  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "|6  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "|7  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "|8  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "|9  |2020-02-09|2020-02-09 10:36:23.987|\n",
            "+---+----------+-----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJGpfTYZCxgh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7fdf568a-2be9-409f-82bd-f838f3da1211"
      },
      "source": [
        "dateDF.createOrReplaceTempView(\"dateDFTable\")\n",
        "dateDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: long (nullable = false)\n",
            " |-- today: date (nullable = false)\n",
            " |-- now: timestamp (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJyWHo0jCxg2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e011d231-c389-41ec-a410-4bf1d6690d1c"
      },
      "source": [
        "from pyspark.sql.functions import date_add, date_sub\n",
        "dateDF.select(date_sub(col(\"today\"), 10),date_add(col(\"today\"), 10)).show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-------------------+\n",
            "|date_sub(today, 10)|date_add(today, 10)|\n",
            "+-------------------+-------------------+\n",
            "|         2020-01-30|         2020-02-19|\n",
            "+-------------------+-------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5eJpy1dCxhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5f0c378a-2db8-4f92-dad9-af170f177f43"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "date_sub(today, 10),\n",
        "date_add(today, 10)\n",
        "FROM\n",
        "dateDFTable\n",
        "\"\"\").show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-------------------+\n",
            "|date_sub(today, 10)|date_add(today, 10)|\n",
            "+-------------------+-------------------+\n",
            "|         2020-01-30|         2020-02-19|\n",
            "+-------------------+-------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrKCJ9-ZCxhm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "afd4a5c1-f0c8-4511-8d1b-5eba7248d465"
      },
      "source": [
        "from pyspark.sql.functions import datediff, months_between, to_date\n",
        "dateDF\\\n",
        ".withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\\\n",
        ".select(datediff(col(\"week_ago\"), col(\"today\")).alias('datediff_today_weekago'))\\\n",
        ".show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+\n",
            "|datediff_today_weekago|\n",
            "+----------------------+\n",
            "|                    -7|\n",
            "+----------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y35UvygCxhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ce85c9f7-0422-44aa-f3e1-e5fe942032f8"
      },
      "source": [
        "dateDF\\\n",
        ".select(\n",
        "to_date(lit(\"2017-01-01\")).alias(\"start\"),\n",
        "to_date(lit(\"2018-02-18\")).alias(\"end\"))\\\n",
        ".select(months_between(col(\"end\"), col(\"start\")))\\\n",
        ".show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------+\n",
            "|months_between(end, start)|\n",
            "+--------------------------+\n",
            "|                13.5483871|\n",
            "+--------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPbD7AecCxhz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "79240a10-ddd1-4b2a-b787-8c80e6e90a21"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "to_date('2016-01-01') AS date,\n",
        "months_between('2017-01-01', '2016-01-01') AS months_between,\n",
        "datediff('2017-01-01', '2016-01-01') AS datediff_days\n",
        "FROM\n",
        "dateDFTable\n",
        "\"\"\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------+-------------+\n",
            "|      date|months_between|datediff_days|\n",
            "+----------+--------------+-------------+\n",
            "|2016-01-01|          12.0|          366|\n",
            "|2016-01-01|          12.0|          366|\n",
            "+----------+--------------+-------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glY0AfWACxiE"
      },
      "source": [
        "__WARNING__\n",
        "<br>Spark will not throw an error if it cannot parse the date, it’ll just return null. This can be a bit tricky in larger pipelines because you may be expecting your data in one format and getting it in another. To illustrate, let’s take a look at the date format that has switched from year-month-day to year-day-month. Spark will fail to parse this date and silently return null instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rorLivMCxiI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5dc5b318-e2c7-4cd2-a637-5ecd5cfe7db1"
      },
      "source": [
        "### 2016-20-12 - year-day-month\n",
        "### 2017-12-11 - year-month-day\n",
        "dateDF.select(to_date(lit(\"2016-20-12\")),to_date(lit(\"2017-12-11\"))).show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------+---------------------+\n",
            "|to_date('2016-20-12')|to_date('2017-12-11')|\n",
            "+---------------------+---------------------+\n",
            "|                 null|           2017-12-11|\n",
            "+---------------------+---------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX2zNKHohaoH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}