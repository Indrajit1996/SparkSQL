{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiSNokEu-jh3"
      },
      "source": [
        "# Spark Operations using Spark DataFrames and Spark SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7g9RloR-oVs",
        "outputId": "5a17585b-f455-459b-924f-702109bc7380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DySqSaZB-vRf"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WALZqGkc-y-m"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkuwl9G7-69C"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wD15War-1wK"
      },
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "      .builder \\\n",
        "      .appName('PySpark on Google Colab') \\\n",
        "      .master('local[*]') \\\n",
        "      .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi28NnPt-jiT"
      },
      "source": [
        "### 0.Set PySpark environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V408jSBl-jij"
      },
      "source": [
        "# import os\n",
        "# import sys\n",
        "# os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
        "# os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
        "# sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.7-src.zip\")\n",
        "# sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq4R6wlO-ji8"
      },
      "source": [
        "### 1.Create  SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3ZDrZdM-jjD"
      },
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark import SparkConf\n",
        "# spark = SparkSession.builder\\\n",
        "#         .appName(\"SparkSQL and SparkData Frames\")\\\n",
        "#         .master('local[*]')\\\n",
        "#         .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdIBShI7-jkx"
      },
      "source": [
        "### 2. Check the Spark Session Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7hwPvJT-jk5",
        "outputId": "8e586404-391b-420c-be1b-0f016a5ec1cb",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c500ac722118:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark on Google Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fb605961438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gFMelno-jlY"
      },
      "source": [
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fyd3zOK-jlr",
        "outputId": "20d81095-e17e-4801-c2d3-df97979dff3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "sc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c500ac722118:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark on Google Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=PySpark on Google Colab>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMt0hauR-jmI"
      },
      "source": [
        "## ** Spark DataFrame **\n",
        "\n",
        "#### A DataFrame is the most common Structured API and simply represents a table of data with rows and columns. \n",
        "<br> The list that defines the columns and the types within those columns is called the schema. \n",
        "<br> One can think of a DataFrame as a spreadsheet with named columns.\n",
        "<br> A spreadsheet sits on one computer in one specific location, whereas a Spark DataFrame can span thousands of computers.\n",
        "<br> The reason for putting the data on more than one computer should be intuitive: \n",
        "<br>     either the data is too large to fit on one machine or \n",
        "<br>     it would simply take too long to perform that computation on one machine.\n",
        "\n",
        "#### NOTE\n",
        "Spark has several core abstractions: Datasets, DataFrames, SQL Tables, and Resilient Distributed Datasets (RDDs). \n",
        "<br> These different abstractions all represent distributed collections of data. \n",
        "<br> The easiest and most efficient are DataFrames, which are available in all languages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5c-Allp-jmO"
      },
      "source": [
        "### 3. Create Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX2-1Tr6-jmU",
        "outputId": "5f2a3b0f-eeed-460c-e09e-ff04ec85ab42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "myDF = spark.createDataFrame([[1, 'Alice', 30],\n",
        "                              [2, 'Bob', 28],\n",
        "                              [3, 'Cathy', 31], \n",
        "                              [4, 'Dave', 56]], ['Id', 'Name', 'Age'])\n",
        "\n",
        "myDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+---+\n",
            "| Id| Name|Age|\n",
            "+---+-----+---+\n",
            "|  1|Alice| 30|\n",
            "|  2|  Bob| 28|\n",
            "|  3|Cathy| 31|\n",
            "|  4| Dave| 56|\n",
            "+---+-----+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSegpnnR-jmr"
      },
      "source": [
        "#### Create Dataframe from an RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s3h_Mub-jm2",
        "outputId": "c42b63a6-1294-4d10-ec82-db88fab6f720",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reading from local file system.\n",
        "#trainRDD = sc.textFile(\"file:///home/thomasj/Batch78/SparkSQL/SalesData/train.csv\")\n",
        "\n",
        "# Read from hdfs file system.\n",
        "trainRDD = sc.textFile(\"drive/My Drive/SparkSQL/data/SalesData/train.csv\")\n",
        "print(\"Total Records with header: \", trainRDD.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Records with header:  550069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83AumuYR-jnH",
        "outputId": "77b0196c-9139-42da-c782-057ad53c3c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(\"\\nFirst Two Records Before Removing Header\\n\")\n",
        "print(trainRDD.take(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "First Two Records Before Removing Header\n",
            "\n",
            "['User_ID,Product_ID,Gender,Age,Occupation,City_Category,Stay_In_Current_City_Years,Marital_Status,Product_Category_1,Product_Category_2,Product_Category_3,Purchase', '1000001,P00069042,F,0-17,10,A,2,0,3,,,8370']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_M5j-os-jnc",
        "outputId": "aa4ea846-9e40-4ed5-f8c0-7ccece643ea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "header = trainRDD.first()\n",
        "header"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'User_ID,Product_ID,Gender,Age,Occupation,City_Category,Stay_In_Current_City_Years,Marital_Status,Product_Category_1,Product_Category_2,Product_Category_3,Purchase'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnQHBJ8V-jnn",
        "outputId": "4039eb66-8075-486d-8a37-847146886494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "trainRDD = trainRDD.filter(lambda line: line != header)\n",
        "print(\"Total Records without header: \", trainRDD.count())\n",
        "print(\"\\nFirst Two Records After Removing Header\\n\")\n",
        "print(trainRDD.take(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Records without header:  550068\n",
            "\n",
            "First Two Records After Removing Header\n",
            "\n",
            "['1000001,P00069042,F,0-17,10,A,2,0,3,,,8370', '1000001,P00248942,F,0-17,10,A,2,0,1,6,14,15200']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-XltAAQ-jnz",
        "outputId": "3335e345-651d-4022-b5cd-088449790fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Split the data into individual columns\n",
        "splitRDD = trainRDD.map(lambda row:row.split(\",\"))\n",
        "print(\"\\nFirst Two Records After Split/Parsing\\n\")\n",
        "print(splitRDD.take(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "First Two Records After Split/Parsing\n",
            "\n",
            "[['1000001', 'P00069042', 'F', '0-17', '10', 'A', '2', '0', '3', '', '', '8370'], ['1000001', 'P00248942', 'F', '0-17', '10', 'A', '2', '0', '1', '6', '14', '15200']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI0w-2Q8-joE"
      },
      "source": [
        "#### Create a dataframe for the above Data\n",
        "1. Define Schema\n",
        "2. Create dataframe using the above schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYHfBBVK-joJ"
      },
      "source": [
        "#### Create Schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjuyljr-joO"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "trainSchema = StructType([\n",
        "    StructField(\"User_ID\", StringType(), True),\n",
        "    StructField(\"Product_ID\", StringType(), True),\n",
        "    StructField(\"Gender\", StringType(), True),\n",
        "    StructField(\"Age\", StringType(), True),\n",
        "    StructField(\"Occupation\", StringType(), True),\n",
        "    StructField(\"City_Category\", StringType(), True),\n",
        "    StructField(\"Stay_In_Current_City_Years\",StringType(),True),\n",
        "    StructField(\"Marital_Status\", StringType(), True),\n",
        "    StructField(\"Product_Category_1\", StringType(), True),\n",
        "    StructField(\"Product_Category_2\", StringType(), True),\n",
        "    StructField(\"Product_Category_3\", StringType(), True),\n",
        "    StructField(\"Purchase\",StringType(),True)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbOB3_1J-joZ"
      },
      "source": [
        "#### Create DataFrame using toDF()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMUYPgvM-joc",
        "outputId": "acd90899-9f8d-4a7b-fdc0-619ddd12ebf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "trainDF = splitRDD.toDF(schema = trainSchema)\n",
        "trainDF.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|                  |                  |    8370|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
            "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|                  |                  |    1422|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|                  |    1057|\n",
            "|1000002| P00285442|     M| 55+|        16|            C|                        4+|             0|                 8|                  |                  |    7969|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__fJF8NI-jon"
      },
      "source": [
        "#### Create DataFrame using createDataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL9x0gBJ-jos",
        "outputId": "79646d87-f447-44b4-844e-c3ec23232d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "trainDF = spark.createDataFrame(data = splitRDD, schema=trainSchema)\n",
        "trainDF.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|                  |                  |    8370|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
            "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|                  |                  |    1422|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|                  |    1057|\n",
            "|1000002| P00285442|     M| 55+|        16|            C|                        4+|             0|                 8|                  |                  |    7969|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsYxbfnt-jo4"
      },
      "source": [
        "### 4. DataFrame Transformations & Actions\n",
        "\n",
        "### Transformations\n",
        "In Spark, the core data structures are immutable, meaning they cannot be changed after they’re created.\n",
        "<br> To “change” a DataFrame, you need to instruct Spark how you would like to modify it to do what you want.\n",
        "<br> These instructions are called transformations.\n",
        "<br> Transformations are the core of how you express your business logic using Spark.\n",
        "<br> Transformations are simply ways of specifying different series of data manipulation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zJDn3LE-jo8"
      },
      "source": [
        "#### Create a dataframe with one column containing 100 rows with values from 0 to 99."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5XQ7pS2-jpB"
      },
      "source": [
        "myRange = spark.range(100).toDF('number')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oJxFDHL-jpL",
        "outputId": "a2558447-036e-4b27-af4a-17f8a345e669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "myRange.show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|number|\n",
            "+------+\n",
            "|     0|\n",
            "|     1|\n",
            "|     2|\n",
            "|     3|\n",
            "|     4|\n",
            "|     5|\n",
            "|     6|\n",
            "|     7|\n",
            "|     8|\n",
            "|     9|\n",
            "+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9aZ4vyS-jpX",
        "outputId": "63d46268-ffcd-4577-a825-27b9dcc04be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "divisBy2 = myRange.where(\"number % 2 = 0\")\n",
        "divisBy2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[number: bigint]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tT8LSFE-jpm"
      },
      "source": [
        "Notice that these return no output. <br>This is because we specified only an abstract transformation, and Spark will not act on transformations until we call an action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEdibedL-jpq"
      },
      "source": [
        "### Actions\n",
        "Transformations allow us to build up our logical transformation plan. \n",
        "<br> To trigger the computation, we run an action.\n",
        "<br> An action instructs Spark to compute a result from a series of transformations. \n",
        "<br> The simplest action is show, which displays the records in the DataFrame\n",
        "\n",
        "#### There are 3 types of actions\n",
        "Actions to view data in the console\n",
        "<br>Actions to collect data \n",
        "<br>Actions to write to output data sources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE8lYcgD-jpt",
        "outputId": "54ee2d1c-5911-47dc-a880-bcfe5f910e25",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "divisBy2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|number|\n",
            "+------+\n",
            "|     0|\n",
            "|     2|\n",
            "|     4|\n",
            "|     6|\n",
            "|     8|\n",
            "|    10|\n",
            "|    12|\n",
            "|    14|\n",
            "|    16|\n",
            "|    18|\n",
            "|    20|\n",
            "|    22|\n",
            "|    24|\n",
            "|    26|\n",
            "|    28|\n",
            "|    30|\n",
            "|    32|\n",
            "|    34|\n",
            "|    36|\n",
            "|    38|\n",
            "+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1cJb0xD-jp5",
        "outputId": "0ea84336-6f1f-4e57-d7cc-582c2cc876bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "divisBy2.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vZttrFM-jqE",
        "outputId": "bafbff4d-5b50-408f-d4c9-fbbd3be11f97",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "trainDF.take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(User_ID='1000001', Product_ID='P00069042', Gender='F', Age='0-17', Occupation='10', City_Category='A', Stay_In_Current_City_Years='2', Marital_Status='0', Product_Category_1='3', Product_Category_2='', Product_Category_3='', Purchase='8370'),\n",
              " Row(User_ID='1000001', Product_ID='P00248942', Gender='F', Age='0-17', Occupation='10', City_Category='A', Stay_In_Current_City_Years='2', Marital_Status='0', Product_Category_1='1', Product_Category_2='6', Product_Category_3='14', Purchase='15200')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awjdWAgo-jqO",
        "outputId": "ca545c6f-fb00-422a-b751-0ddd3aa12abd",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "trainDF.show(4,truncate=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|                  |                  |    8370|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
            "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|                  |                  |    1422|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|                  |    1057|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBjrljwj-jqe",
        "outputId": "dcbaa181-d0da-49de-98a3-54c3be077e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainDF.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "550068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lwuJKlr-jqq"
      },
      "source": [
        "### 5. Reading a CSV file into a DataFrame "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkGcQyj4-jqs"
      },
      "source": [
        "path = \"drive/My Drive/SparkSQL/data/SalesData/train.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG12oXII-jq-"
      },
      "source": [
        "trainDF = spark.read.csv(path=path,header=True,sep=\",\", inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKhgYzYT-jsf",
        "outputId": "bcdfd958-c422-495f-819c-65a872a2dad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "trainDF.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(User_ID=1000001, Product_ID='P00069042', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=3, Product_Category_2=None, Product_Category_3=None, Purchase=8370),\n",
              " Row(User_ID=1000001, Product_ID='P00248942', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=1, Product_Category_2=6, Product_Category_3=14, Purchase=15200),\n",
              " Row(User_ID=1000001, Product_ID='P00087842', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=12, Product_Category_2=None, Product_Category_3=None, Purchase=1422),\n",
              " Row(User_ID=1000001, Product_ID='P00085442', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=12, Product_Category_2=14, Product_Category_3=None, Purchase=1057),\n",
              " Row(User_ID=1000002, Product_ID='P00285442', Gender='M', Age='55+', Occupation=16, City_Category='C', Stay_In_Current_City_Years='4+', Marital_Status=0, Product_Category_1=8, Product_Category_2=None, Product_Category_3=None, Purchase=7969)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhTen-qO-jsv",
        "outputId": "1135c42e-7747-4d39-9ea6-5ad4f4dedebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "trainDF.show(5,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender|Age |Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001|P00069042 |F     |0-17|10        |A            |2                         |0             |3                 |null              |null              |8370    |\n",
            "|1000001|P00248942 |F     |0-17|10        |A            |2                         |0             |1                 |6                 |14                |15200   |\n",
            "|1000001|P00087842 |F     |0-17|10        |A            |2                         |0             |12                |null              |null              |1422    |\n",
            "|1000001|P00085442 |F     |0-17|10        |A            |2                         |0             |12                |14                |null              |1057    |\n",
            "|1000002|P00285442 |M     |55+ |16        |C            |4+                        |0             |8                 |null              |null              |7969    |\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLjH4HcM-js7",
        "outputId": "2680a72f-0297-4f6c-af3b-452a3b42fff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "trainDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- User_ID: integer (nullable = true)\n",
            " |-- Product_ID: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Occupation: integer (nullable = true)\n",
            " |-- City_Category: string (nullable = true)\n",
            " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
            " |-- Marital_Status: integer (nullable = true)\n",
            " |-- Product_Category_1: integer (nullable = true)\n",
            " |-- Product_Category_2: integer (nullable = true)\n",
            " |-- Product_Category_3: integer (nullable = true)\n",
            " |-- Purchase: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C2GqK5h-jtM"
      },
      "source": [
        "#### Getting the  shape of the spark data frame\n",
        "* As such there is no shape command directly in spark we need to get it from the length of columns and \n",
        "  count of records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmipXp73-jtP",
        "outputId": "f27710d7-89c7-4c29-f4e1-f3ae606b996e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## To Count the number of rows in DataFrame\n",
        "print('Total records count in train dataset is {}'.format(trainDF.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total records count in train dataset is 550068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfRG8pyN-jte",
        "outputId": "f7b7720b-5778-41ce-9a03-3afcbadaac62",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "## Columns count and column names\n",
        "print(\"Total Columns count in train dataset is {}\".format(len(trainDF.columns)))\n",
        "print(\"\\n\\nColumns in train dataset are: {} \\n\".format(trainDF.columns))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Columns count in train dataset is 12\n",
            "\n",
            "\n",
            "Columns in train dataset are: ['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3', 'Purchase'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ssjNmar-jtm"
      },
      "source": [
        "### 6. Verify Schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inBQ6mXw-jtp",
        "outputId": "01fb926f-b086-4d51-a07c-d3a31cc8d2c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "## Print Schema\n",
        "trainDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- User_ID: integer (nullable = true)\n",
            " |-- Product_ID: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Occupation: integer (nullable = true)\n",
            " |-- City_Category: string (nullable = true)\n",
            " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
            " |-- Marital_Status: integer (nullable = true)\n",
            " |-- Product_Category_1: integer (nullable = true)\n",
            " |-- Product_Category_2: integer (nullable = true)\n",
            " |-- Product_Category_3: integer (nullable = true)\n",
            " |-- Purchase: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgfKk2ka-jt2",
        "outputId": "31ddee1c-2a9b-4df0-9916-e2d90ee115f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "trainDF.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('User_ID', 'int'),\n",
              " ('Product_ID', 'string'),\n",
              " ('Gender', 'string'),\n",
              " ('Age', 'string'),\n",
              " ('Occupation', 'int'),\n",
              " ('City_Category', 'string'),\n",
              " ('Stay_In_Current_City_Years', 'string'),\n",
              " ('Marital_Status', 'int'),\n",
              " ('Product_Category_1', 'int'),\n",
              " ('Product_Category_2', 'int'),\n",
              " ('Product_Category_3', 'int'),\n",
              " ('Purchase', 'int')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n93F46yw-juA"
      },
      "source": [
        "#### Getting the Columns from the SparkDataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO-TdrNQ-juG",
        "outputId": "d8af4f68-320e-440b-c641-195cab76d960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "trainDF.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['User_ID',\n",
              " 'Product_ID',\n",
              " 'Gender',\n",
              " 'Age',\n",
              " 'Occupation',\n",
              " 'City_Category',\n",
              " 'Stay_In_Current_City_Years',\n",
              " 'Marital_Status',\n",
              " 'Product_Category_1',\n",
              " 'Product_Category_2',\n",
              " 'Product_Category_3',\n",
              " 'Purchase']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYBGjxFI-juR",
        "outputId": "e47042b3-4860-4e62-994f-af333ea68b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "type(trainDF.columns)\n",
        "trainDF.take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(User_ID=1000001, Product_ID='P00069042', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=3, Product_Category_2=None, Product_Category_3=None, Purchase=8370),\n",
              " Row(User_ID=1000001, Product_ID='P00248942', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=1, Product_Category_2=6, Product_Category_3=14, Purchase=15200)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUbgtCko-jud"
      },
      "source": [
        "### 7.To Show first n observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1neuhXU-juf",
        "outputId": "c2fc2e88-02b0-43de-c5ff-fffd40277fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "## Use head operation to see first n observations (say, 2 observations). \n",
        "## Head operation in PySpark is similar to head operation in Pandas.\n",
        "trainDF.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(User_ID=1000001, Product_ID='P00069042', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=3, Product_Category_2=None, Product_Category_3=None, Purchase=8370),\n",
              " Row(User_ID=1000001, Product_ID='P00248942', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=1, Product_Category_2=6, Product_Category_3=14, Purchase=15200)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_m_0YgR-juq",
        "outputId": "7273b9b8-ad1a-44d0-94ea-221f6dc95d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "## Above results are comprised of row like format. \n",
        "## To see the result in more interactive manner (rows under the columns), Use the show operation. \n",
        "## Show operation on train and take first 5 rows of it. \n",
        "trainDF.show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnYYESqs-jvO"
      },
      "source": [
        "### 8.Summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hI77Kd6-jvU",
        "outputId": "483efbe1-c814-4818-cbe0-478e58efddc9",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "## To get the summary statistics (mean, standard deviance, min ,max , count) of numerical columns in a DataFrame\n",
        "trainDF.describe().show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
            "|summary|User_ID           |Product_ID|Gender|Age   |Occupation       |City_Category|Stay_In_Current_City_Years|Marital_Status     |Product_Category_1|Product_Category_2|Product_Category_3|Purchase         |\n",
            "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
            "|count  |550068            |550068    |550068|550068|550068           |550068       |550068                    |550068             |550068            |376430            |166821            |550068           |\n",
            "|mean   |1003028.8424013031|null      |null  |null  |8.076706879876669|null         |1.468494139793958         |0.40965298835780306|5.404270017525106 |9.842329251122386 |12.668243206790512|9263.968712959126|\n",
            "|stddev |1727.5915855313747|null      |null  |null  |6.522660487341741|null         |0.9890866807573103        |0.4917701263173315 |3.936211369201365 |5.086589648693497 |4.125337631575274 |5023.065393820575|\n",
            "|min    |1000001           |P00000142 |F     |0-17  |0                |A            |0                         |0                  |1                 |2                 |3                 |12               |\n",
            "|max    |1006040           |P0099942  |M     |55+   |20               |C            |4+                        |1                  |20                |18                |18                |23961            |\n",
            "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JErmpBmE-jvm",
        "outputId": "9ea2d6ce-c260-4f36-98ec-de6d43dadee5",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "## Check what happens when we specify the name of a categorical / String columns in describe operation.\n",
        "## describe operation is working for String type column but the output for mean, stddev are null and \n",
        "## min & max values are calculated based on ASCII value of categories.\n",
        "trainDF.describe(['Purchase']).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------------+\n",
            "|summary|         Purchase|\n",
            "+-------+-----------------+\n",
            "|  count|           550068|\n",
            "|   mean|9263.968712959126|\n",
            "| stddev|5023.065393820575|\n",
            "|    min|               12|\n",
            "|    max|            23961|\n",
            "+-------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAR3Dmwz-jv3"
      },
      "source": [
        "### 9. a. Adding Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96qVRmJk-jv5",
        "outputId": "d8abc337-db1a-443e-d701-099f2800049e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "## More Formal way\n",
        "from pyspark.sql.functions import lit\n",
        "trainDF.withColumn(\"Year\", lit(\"2019\")).show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|Year|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|2019|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|2019|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50mQ-Pma-jwW",
        "outputId": "378925c7-c39f-48ef-f9c2-7147daa96803",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "tempDF = trainDF.withColumn(\"SameCategoryCode\", \n",
        "trainDF[\"Product_Category_1\"] == trainDF[\"Product_Category_2\"])\n",
        "tempDF.show(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----------------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|SameCategoryCode|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----------------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|            null|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|           false|\n",
            "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|            null|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|           false|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiT70HUI-jwn"
      },
      "source": [
        "### 9.b.Renaming Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlXccuEb-jwr",
        "scrolled": false
      },
      "source": [
        "tempDF = tempDF.withColumnRenamed(\"SameCategoryCode\", \"SimilarCategory\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDIk3Ygo-jxE",
        "outputId": "d533bcdc-3f58-4cad-d51b-98c73f0088c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "tempDF.show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+---------------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|SimilarCategory|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+---------------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|           null|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          false|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+---------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpZ102hH-jxY"
      },
      "source": [
        "### 9.c.Removing Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_NQsH5D-jxa",
        "outputId": "ecfba2fc-d502-4d6c-ae8c-95538b578bcf",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "tempDF.drop(\"SimilarCategory\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
            "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGXQ38_E-jxl"
      },
      "source": [
        "### 10. Changing a Column’s Type (cast)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvxQNJHj-jxm",
        "outputId": "e84c2a61-3e76-40f7-8403-9a967199de90",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "trainDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- User_ID: integer (nullable = true)\n",
            " |-- Product_ID: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Occupation: integer (nullable = true)\n",
            " |-- City_Category: string (nullable = true)\n",
            " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
            " |-- Marital_Status: integer (nullable = true)\n",
            " |-- Product_Category_1: integer (nullable = true)\n",
            " |-- Product_Category_2: integer (nullable = true)\n",
            " |-- Product_Category_3: integer (nullable = true)\n",
            " |-- Purchase: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXB7lmYc-jxv"
      },
      "source": [
        "trainDF = trainDF.withColumn(\"Purchase\",trainDF.Purchase.cast(IntegerType()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDhjzb9O-jx3"
      },
      "source": [
        "### 11. Splitting the data into Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anVloQ_G-jx7",
        "outputId": "d47d0562-d0ab-4536-b397-68221102a146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "trainDF,testDF, testDF2  = trainDF.randomSplit([0.4, 0.3, 0.3], seed=1234)\n",
        "print(trainDF.count())\n",
        "print(testDF.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "220514\n",
            "164951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9lj2NA6-jyH"
      },
      "source": [
        "### 12. Working with Nulls in Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ngttwfG-jyJ",
        "outputId": "61996e01-29c3-4a90-a634-c27e8c0d512e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "trainDF.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in trainDF.columns]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+---+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender|Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+---+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|      0|         0|     0|  0|         0|            0|                         0|             0|                 0|             69456|            153673|       0|\n",
            "+-------+----------+------+---+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfUzKZl6-jyS"
      },
      "source": [
        "#### To drop the all rows with null value?\n",
        "##### Use **dropna()** operation. \n",
        "  To drop row from the DataFrame it consider three options.\n",
        "* **how** – ‘any’ or ‘all’. If ‘any’, drop a row if it contains any nulls. If ‘all’, drop a row only if all its values are null.\n",
        "\n",
        "* **thresh** – int, default None If specified, drop rows that have less than thresh non-null values.This overwrites the how parameter.\n",
        "\n",
        "* **subset** – optional list of column names to consider.\n",
        "\n",
        "#### Drop null rows in train with default parameters and count the rows in output DataFrame. \n",
        "#### Default options are any, None, None for how, thresh, subset respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4qteC-v-jyV",
        "outputId": "60829384-f1f9-49a8-ef1f-b1bc69208a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(trainDF.dropna().count())\n",
        "print(trainDF.na.drop().count())\n",
        "print(trainDF.na.drop(\"any\").count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66841\n",
            "66841\n",
            "66841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I987-uAt-jyb",
        "scrolled": true
      },
      "source": [
        "#### To replace the null values in DataFrame with constant number\n",
        "#### Use **fillna()** operation. \n",
        "\n",
        " The fillna will take two parameters to fill the null values.\n",
        "* **value**:\n",
        "    - It will take a dictionary to specify which column will replace with which value.A value (int , float, string) for all columns.\n",
        "* **subset**: Specify some selected columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfAdtLaL-jye",
        "outputId": "008604d5-c06b-4486-b55a-158bf8af8953",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "##Fill ‘-1’ inplace of null values in train DataFrame.\n",
        "trainDF.fillna(-1).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00059442|     F|0-17|        10|            A|                         2|             0|                 6|                 8|                16|   16622|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|                -1|    1057|\n",
            "|1000001| P00111842|     F|0-17|        10|            A|                         2|             0|                 8|                -1|                -1|    8094|\n",
            "|1000001| P00165942|     F|0-17|        10|            A|                         2|             0|                 8|                -1|                -1|   10003|\n",
            "|1000001| P00178242|     F|0-17|        10|            A|                         2|             0|                 8|                -1|                -1|    9946|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeQ1tEMD-jyl",
        "outputId": "06692fbe-ed1a-43d7-ed8f-abdfaf76a593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Filling with different values for different columns\n",
        "fill_cols_vals = {\n",
        "\"Gender\": 'M',\n",
        "\"Purchase\" : 999999\n",
        "}\n",
        "trainDF.na.fill(fill_cols_vals).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tdVNHTw-jyr"
      },
      "source": [
        "### 13. Distinct Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcl5sYXY-jyt",
        "outputId": "d9ff8f9f-4aef-4253-d16c-82037704f803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## To find the number of distinct product in train and test datasets\n",
        "## To calculate the number of distinct products in train and test datasets apply distinct operation.\n",
        "print(\"Distinct values in Product_ID's in train dataset are {}\".format(trainDF.select('Product_ID').distinct().count()))\n",
        "print(\"Distinct values in Product_ID's in test dataset are {}\".format(testDF.select('Product_ID').distinct().count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distinct values in Product_ID's in train dataset are 3490\n",
            "Distinct values in Product_ID's in test dataset are 3430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDWmvyV6-jyz"
      },
      "source": [
        "#### Differences in two columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhYT6rPM-jy1",
        "outputId": "c4f58c1c-a974-4d9c-8062-46d424cbbe2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## From the above we can see the train file has more categories than test file. \n",
        "## Let us check what are the categories for Product_ID, which are in test file but not in train file by \n",
        "## applying subtract operation.\n",
        "## We can do the same for all categorical features.\n",
        "diff_cat_in_test_train=testDF.select('Product_ID').subtract(trainDF.select('Product_ID'))\n",
        "print(\"Count of Product_ID's there in test dataset but not train dataset are {}\".format(diff_cat_in_test_train.count()))\n",
        "\n",
        "diff_cat_in_train_test=trainDF.select('Product_ID').subtract(testDF.select('Product_ID'))\n",
        "print(\"Count of Product_ID's there in train dataset but not test dataset are {}\".format(diff_cat_in_train_test.count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Product_ID's there in test dataset but not train dataset are 83\n",
            "Count of Product_ID's there in train dataset but not test dataset are 143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCTfX5W6-jzI"
      },
      "source": [
        "### 14. Using Spark SQL \n",
        "With Spark SQL, you can register any DataFrame as a table or view (a temporary table) and query it using pure SQL. \n",
        "<br>There is no performance difference between writing SQL queries or writing DataFrame code, <br>they both “compile” to the same underlying plan that we specify in DataFrame code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlL0NH7I-jzM"
      },
      "source": [
        "## Create view/table\n",
        "trainDF.createOrReplaceTempView(\"trainDFTable\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo5UG76t-jzV",
        "outputId": "368c3261-6771-40f2-ced1-ceddb45353f3",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "## Verify Table\n",
        "spark.sql(\"SELECT * FROM trainDFTable LIMIT 2\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "|1000001| P00059442|     F|0-17|        10|            A|                         2|             0|                 6|                 8|                16|   16622|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1JiuGyz-jzh"
      },
      "source": [
        "#### Column References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9krWB9M-jzk"
      },
      "source": [
        "#### Select & SelectExpr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_v51xRx-jzp",
        "outputId": "1f2c74df-901b-4c35-8c32-74de337b6d3c",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "## Multiple ways of referring a column in a dataframe\n",
        "from pyspark.sql.functions import expr, col, column\n",
        "\n",
        "trainDF.select(expr(\"User_ID AS userID\") , col(\"User_ID\"), \n",
        "               column(\"User_ID\"), \"User_ID\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+-------+-------+\n",
            "| userID|User_ID|User_ID|User_ID|\n",
            "+-------+-------+-------+-------+\n",
            "|1000001|1000001|1000001|1000001|\n",
            "|1000001|1000001|1000001|1000001|\n",
            "+-------+-------+-------+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X87c3HZx-jzv"
      },
      "source": [
        "#### Pandas dot notation doesn't work here "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uFvpYMZ-jzx"
      },
      "source": [
        "result = trainDF.User_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8dGwlZX-jz9"
      },
      "source": [
        "This will save/assign a column name to the newly created variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wofO01n-jz-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9c704866-8629-45ac-eb11-d7c27c763f27"
      },
      "source": [
        "# select content from the above column\n",
        "trainDF.select(result).show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+\n",
            "|User_ID|\n",
            "+-------+\n",
            "|1000001|\n",
            "|1000001|\n",
            "+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XU5cIkf-j0P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "13f18d93-cf29-4bde-9cbf-02d979eddd39"
      },
      "source": [
        "spark.sql(\"SELECT User_ID AS userID FROM trainDFTable\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+\n",
            "| userID|\n",
            "+-------+\n",
            "|1000001|\n",
            "|1000001|\n",
            "+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syALY44m-j0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "85f9d609-84f2-4c37-d840-da1fae657882"
      },
      "source": [
        "trainDF.selectExpr(\"User_ID AS userID\", \"Product_ID AS productID\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+---------+\n",
            "| userID|productID|\n",
            "+-------+---------+\n",
            "|1000001|P00059442|\n",
            "|1000001|P00085442|\n",
            "+-------+---------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQHvPEMd-j0c"
      },
      "source": [
        "#### Converting to Spark Types (Literals)\n",
        "Sometimes we need to pass explicit values into Spark that aren’t a new column but are just a value in all the rows. This might be a constant value or something we’ll need to compare to later on. The way we do this is through literals. \n",
        "This is basically a translation from a given programming language’s literal value to one that Spark understands. \n",
        "Literals are expressions and can be used in the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EnNx776-j0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "3775e366-faa7-4292-a58c-b7b8382aaccf"
      },
      "source": [
        "from pyspark.sql.functions import lit\n",
        "trainDF.select(\"*\", lit(1).alias('One')).show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+---+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|One|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+---+\n",
            "|1000001| P00059442|     F|0-17|        10|            A|                         2|             0|                 6|                 8|                16|   16622|  1|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|  1|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+---+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVh4u4Dd-j0j",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "7840a386-71a4-4b62-e424-7846e35b65ea"
      },
      "source": [
        "## In SQL, literals are just the specific value.\n",
        "trainDF.createOrReplaceTempView('trainDFTable')\n",
        "spark.sql(\"SELECT *, 2019 as Year FROM trainDFTable LIMIT 2\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----+\n",
            "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|Year|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----+\n",
            "|1000001| P00059442|     F|0-17|        10|            A|                         2|             0|                 6|                 8|                16|   16622|2019|\n",
            "|1000001| P00085442|     F|0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|2019|\n",
            "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhDpQFEJ-j0o"
      },
      "source": [
        "#### Pair wise Frequencies - Crosstab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0njG1qa-j0r",
        "outputId": "0a68d7c2-d790-445d-d150-a25a01aed5b7",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "## To calculate pair wise frequency of categorical columns\n",
        "## Use crosstab operation on DataFrame to calculate the pair wise frequency of columns. \n",
        "## Apply crosstab operation on ‘Age’ and ‘Gender’ columns of train DataFrame.\n",
        "trainDF.crosstab('Gender', 'Age').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----+-----+-----+-----+-----+-----+----+\n",
            "|Gender_Age|0-17|18-25|26-35|36-45|46-50|51-55| 55+|\n",
            "+----------+----+-----+-----+-----+-----+-----+----+\n",
            "|         M|4014|30307|67844|33112|13017|11410|6599|\n",
            "|         F|1976| 9926|20151|10849| 5258| 4021|2030|\n",
            "+----------+----+-----+-----+-----+-----+-----+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw77cZtx-j0z",
        "outputId": "604ba510-1ad3-4137-fb08-380fcda4044a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "trainDF.groupBy('Age', 'Gender').count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+-----+\n",
            "|  Age|Gender|count|\n",
            "+-----+------+-----+\n",
            "|51-55|     F| 4021|\n",
            "|18-25|     M|30307|\n",
            "| 0-17|     F| 1976|\n",
            "|46-50|     M|13017|\n",
            "|18-25|     F| 9926|\n",
            "|  55+|     M| 6599|\n",
            "|  55+|     F| 2030|\n",
            "|36-45|     M|33112|\n",
            "|26-35|     F|20151|\n",
            "| 0-17|     M| 4014|\n",
            "|36-45|     F|10849|\n",
            "|51-55|     M|11410|\n",
            "|26-35|     M|67844|\n",
            "|46-50|     F| 5258|\n",
            "+-----+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcB36yUL-j08",
        "outputId": "fe306eb2-25a0-4f6e-cd75-278bc9682af8",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "spark.sql(\"\"\"select Age,\n",
        "    sum(case when Gender = 'F' then 1 else 0 end) F,\n",
        "    sum(case when Gender = 'M' then 1 else 0 end) M\n",
        "from trainDFTable\n",
        "group by Age\"\"\").show()\n",
        "\n",
        "# spark.sql(\"\"\"select Age,\n",
        "#     count(*) total,\n",
        "#     sum(case when Gender = 'F' then 1 else 0 end) F,\n",
        "#     sum(case when Gender = 'M' then 1 else 0 end) M\n",
        "# from trainDFTable\n",
        "# group by Age\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+-----+\n",
            "|  Age|    F|    M|\n",
            "+-----+-----+-----+\n",
            "|18-25| 9926|30307|\n",
            "|26-35|20151|67844|\n",
            "| 0-17| 1976| 4014|\n",
            "|46-50| 5258|13017|\n",
            "|51-55| 4021|11410|\n",
            "|36-45|10849|33112|\n",
            "|  55+| 2030| 6599|\n",
            "+-----+-----+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "573SfK96-j1F"
      },
      "source": [
        "#### Removing Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOZRV5KG-j1I",
        "outputId": "9a46f030-416c-4642-b6aa-1906a0cd4838",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "##To get the DataFrame without any duplicate rows of given a DataFrame\n",
        "##Use dropDuplicates operation to drop the duplicate rows of a DataFrame. \n",
        "## In this command, performing this on two columns Age and Gender of train dataset and \n",
        "## Get the all unique rows for these two columns.\n",
        "trainDF.select('Age','Gender').dropDuplicates().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|  Age|Gender|\n",
            "+-----+------+\n",
            "|51-55|     F|\n",
            "|18-25|     M|\n",
            "| 0-17|     F|\n",
            "|46-50|     M|\n",
            "|18-25|     F|\n",
            "|  55+|     M|\n",
            "|  55+|     F|\n",
            "|36-45|     M|\n",
            "|26-35|     F|\n",
            "| 0-17|     M|\n",
            "|36-45|     F|\n",
            "|51-55|     M|\n",
            "|26-35|     M|\n",
            "|46-50|     F|\n",
            "+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn6qq_7L-j1P"
      },
      "source": [
        "#### Filtering the rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYrvCNOp-j1X",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6c47ebdd-5fef-4d2b-d800-8884b39c5620"
      },
      "source": [
        "## To filter the rows in train dataset which has Purchases more than 15000\n",
        "## apply the filter operation on Purchase column in train DataFrame \n",
        "## to filter out the rows with values more than 15000. \n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(trainDF.Purchase > 15000).count()))\n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(col(\"Purchase\") > 15000).count()))\n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(column(\"Purchase\") > 15000).count()))\n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(expr(\"Purchase\") > 15000).count()))\n",
        "print(\"Count of rows where Purchase Amount more than 15000 are {}\".format(trainDF.filter(trainDF[\"Purchase\"] > 15000).count()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of rows where Purchase Amount more than 15000 are 44075\n",
            "Count of rows where Purchase Amount more than 15000 are 44075\n",
            "Count of rows where Purchase Amount more than 15000 are 44075\n",
            "Count of rows where Purchase Amount more than 15000 are 44075\n",
            "Count of rows where Purchase Amount more than 15000 are 44075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_WjYqyN-j1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "38a7f0e7-1126-4f42-b682-71e58cf73c49"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT \n",
        "COUNT(*) AS Count\n",
        "FROM trainDFTable\n",
        "WHERE Purchase > 15000\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|Count|\n",
            "+-----+\n",
            "|44075|\n",
            "+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl5cOPj7-j1v",
        "outputId": "45fd38e7-aa65-4d32-f774-9181b9a89868",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainDF.where(\"Purchase > 15000\").where(\"Gender = 'F'\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3qvzCQh-j14",
        "outputId": "5ca42b46-734e-473d-e4c1-3291bd3c6207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainDF.filter(\"Purchase > 15000\").where(\"Gender = 'F'\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU2eUkLQ-j2B",
        "outputId": "cc682d5b-090b-41c4-86a5-c5b40816eca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainDF.where((col(\"Purchase\") > 15000) & (col(\"Gender\") == 'F')).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge8SOwPv-j2L",
        "outputId": "cfb2a91f-cd8b-46d7-ad50-fc927b51e2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainDF.filter((col(\"Purchase\") > 15000) & (col(\"Gender\") == 'F')).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOZImx0c-j2T",
        "outputId": "d8509aee-039a-411c-8971-d046930ef86c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spark.sql(\"SELECT * FROM trainDFTable WHERE Purchase > 15000 AND Gender = 'F'\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXAC8d9i-j2Y"
      },
      "source": [
        "### 15. Aggregations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWYLF2XZ-j2a"
      },
      "source": [
        "#### Count Distinct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEk1H-5J-j2c",
        "outputId": "d7aa59c1-8d7d-47dd-9bc6-62ea5eaab0a7",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "trainDF.select(countDistinct(\"Age\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+\n",
            "|count(DISTINCT Age)|\n",
            "+-------------------+\n",
            "|                  7|\n",
            "+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ft7RMt8-j2j"
      },
      "source": [
        "#### Approximate Count Distinct\n",
        "* **Parameters:**\n",
        "    * col - Name of the column\n",
        "    * rsd – maximum estimation error allowed (default = 0.05)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENkzoMic-j2k",
        "outputId": "87aafe50-ab35-44a6-9a9e-d06b6436956b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import approx_count_distinct\n",
        "trainDF.select(approx_count_distinct(col=\"Age\", rsd=0.1)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------+\n",
            "|approx_count_distinct(Age)|\n",
            "+--------------------------+\n",
            "|                         7|\n",
            "+--------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G_3shmy-j2q"
      },
      "source": [
        "#### First and Last"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huJdNICv-j2s",
        "outputId": "398ff0c9-7199-4946-8829-f294e801c066",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import first, last\n",
        "trainDF.select(first(\"Product_ID\", ignorenulls = True), last(\"Product_ID\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+-----------------------+\n",
            "|first(Product_ID, true)|last(Product_ID, false)|\n",
            "+-----------------------+-----------------------+\n",
            "|              P00059442|              P00349442|\n",
            "+-----------------------+-----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i5LxjgJ-j20"
      },
      "source": [
        "#### Min and Max"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKYLIWKq-j22",
        "outputId": "acd8bbae-5838-4233-c287-5725513e25de",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import min, max\n",
        "trainDF.select(min(\"Purchase\"), max(\"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+-------------+\n",
            "|min(Purchase)|max(Purchase)|\n",
            "+-------------+-------------+\n",
            "|           12|        23961|\n",
            "+-------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZDU7GGm-j3B"
      },
      "source": [
        "#### Sum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exUcgv5d-j3D",
        "outputId": "422ff138-6248-48bf-d63a-21b5e9079a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import sum\n",
        "trainDF.select(sum(\"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+\n",
            "|sum(Purchase)|\n",
            "+-------------+\n",
            "|   2039763128|\n",
            "+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmxiXnfz-j3J"
      },
      "source": [
        "#### sumDistinct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXgHPRJV-j3L",
        "outputId": "00d45107-83f2-43c4-e81b-f591e5403af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import sumDistinct\n",
        "trainDF.select(sumDistinct(\"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+\n",
            "|sum(DISTINCT Purchase)|\n",
            "+----------------------+\n",
            "|             180521433|\n",
            "+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FG0Kk6g-j3Z"
      },
      "source": [
        "#### Avg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKTB2zN2-j3c",
        "outputId": "724df55b-8d40-4193-8a48-c481cea8b590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import sum, count, avg, expr\n",
        "\n",
        "trainDF.select(\n",
        "    count(\"Purchase\").alias(\"total_transactions\"),\n",
        "    sum(\"Purchase\").alias(\"total_purchases\"),\n",
        "    avg(\"Purchase\").alias(\"avg_purchases\"),\n",
        "    expr(\"mean(Purchase)\").alias(\"mean_purchases\"))\\\n",
        "  .selectExpr(\n",
        "    \"total_purchases/total_transactions\",\n",
        "    \"avg_purchases\",\n",
        "    \"mean_purchases\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------+-----------------+-----------------+\n",
            "|(total_purchases / total_transactions)|    avg_purchases|   mean_purchases|\n",
            "+--------------------------------------+-----------------+-----------------+\n",
            "|                     9250.039126767462|9250.039126767462|9250.039126767462|\n",
            "+--------------------------------------+-----------------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGid8uOC-j3w"
      },
      "source": [
        "#### Variance and Standard Deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsnmZ0dm-j30",
        "outputId": "7a8d4503-7c44-47ef-e74c-f26a9ab30b6a",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import var_pop, stddev_pop\n",
        "from pyspark.sql.functions import var_samp, stddev_samp\n",
        "\n",
        "trainDF.select(var_pop(\"Purchase\"), var_samp(\"Purchase\"),\n",
        "  stddev_pop(\"Purchase\"), stddev_samp(\"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-------------------+--------------------+---------------------+\n",
            "|  var_pop(Purchase)| var_samp(Purchase)|stddev_pop(Purchase)|stddev_samp(Purchase)|\n",
            "+-------------------+-------------------+--------------------+---------------------+\n",
            "|2.515591314684939E7|2.515602722589755E7|   5015.567081282972|    5015.578453767576|\n",
            "+-------------------+-------------------+--------------------+---------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NY4Mik_-j39",
        "outputId": "307b81dc-e55e-43dc-9fb6-ee952549b0f2",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT var_pop(Purchase), var_samp(Purchase),\n",
        "             stddev_pop(Purchase), stddev_samp(Purchase)\n",
        "             FROM trainDFTable\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------+----------------------------------+------------------------------------+-------------------------------------+\n",
            "|var_pop(CAST(Purchase AS DOUBLE))|var_samp(CAST(Purchase AS DOUBLE))|stddev_pop(CAST(Purchase AS DOUBLE))|stddev_samp(CAST(Purchase AS DOUBLE))|\n",
            "+---------------------------------+----------------------------------+------------------------------------+-------------------------------------+\n",
            "|              2.515591314684939E7|               2.515602722589755E7|                   5015.567081282972|                    5015.578453767576|\n",
            "+---------------------------------+----------------------------------+------------------------------------+-------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q--JUZIw-j4J"
      },
      "source": [
        "#### skewness and kurtosis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AAckd90-j4M",
        "outputId": "9b27abaf-7270-4f56-82f1-a5b217816eaf",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import skewness, kurtosis\n",
        "trainDF.select(skewness(\"Purchase\"), kurtosis(\"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+-------------------+\n",
            "|skewness(Purchase)| kurtosis(Purchase)|\n",
            "+------------------+-------------------+\n",
            "|0.6025760119887242|-0.3280309873336331|\n",
            "+------------------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3tLXThR-j4W",
        "outputId": "93ee8306-eae0-41fc-8d9f-eb86004171a0",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT skewness(Purchase), kurtosis(Purchase)\n",
        "             FROM trainDFTable\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------+----------------------------------+\n",
            "|skewness(CAST(Purchase AS DOUBLE))|kurtosis(CAST(Purchase AS DOUBLE))|\n",
            "+----------------------------------+----------------------------------+\n",
            "|                0.6025760119887242|               -0.3280309873336331|\n",
            "+----------------------------------+----------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut702cyt-j4b"
      },
      "source": [
        "#### Covariance and Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUSNaGId-j4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4f64d4ea-7df8-409a-b4d0-2c8e3a87d122"
      },
      "source": [
        "from pyspark.sql.functions import corr, covar_pop, covar_samp\n",
        "trainDF.select(corr(\"Product_Category_1\", \"Purchase\"), covar_samp(\"Product_Category_1\", \"Purchase\"),\n",
        "    covar_pop(\"Product_Category_1\", \"Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------+----------------------------------------+---------------------------------------+\n",
            "|corr(Product_Category_1, Purchase)|covar_samp(Product_Category_1, Purchase)|covar_pop(Product_Category_1, Purchase)|\n",
            "+----------------------------------+----------------------------------------+---------------------------------------+\n",
            "|              -0.34450360021154175|                       -6796.78011329084|                     -6796.749290848214|\n",
            "+----------------------------------+----------------------------------------+---------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjIOwd1r-j4i",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ffb9b1e7-9d99-4e94-9790-0e9472270a3e"
      },
      "source": [
        "spark.sql(\"\"\"SELECT corr(Product_Category_1, Purchase), covar_samp(Product_Category_1, Purchase),\n",
        "             covar_pop(Product_Category_1, Purchase)\n",
        "             FROM trainDFTable\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------+------------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
            "|corr(CAST(Product_Category_1 AS DOUBLE), CAST(Purchase AS DOUBLE))|covar_samp(CAST(Product_Category_1 AS DOUBLE), CAST(Purchase AS DOUBLE))|covar_pop(CAST(Product_Category_1 AS DOUBLE), CAST(Purchase AS DOUBLE))|\n",
            "+------------------------------------------------------------------+------------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
            "|                                              -0.34450360021154175|                                                       -6796.78011329084|                                                     -6796.749290848214|\n",
            "+------------------------------------------------------------------+------------------------------------------------------------------------+-----------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GusfOAvm-j4t"
      },
      "source": [
        "#### Complex Aggregations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nwn1AOi-j4u",
        "outputId": "1aef5248-8baf-4985-a12d-5b2bef160138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.sql.functions import collect_set, collect_list\n",
        "trainDF.agg(collect_set(\"Age\"), collect_list(\"Age\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|    collect_set(Age)|   collect_list(Age)|\n",
            "+--------------------+--------------------+\n",
            "|[55+, 51-55, 0-17...|[0-17, 0-17, 0-17...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV-m6g6X-j44",
        "outputId": "56560e9e-0547-4960-9248-f87381d5c205",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "spark.sql(\"\"\"SELECT collect_set(Age), collect_list(Age) FROM trainDFTable\"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|    collect_set(Age)|   collect_list(Age)|\n",
            "+--------------------+--------------------+\n",
            "|[55+, 51-55, 0-17...|[0-17, 0-17, 0-17...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOTwha2V-j5Q"
      },
      "source": [
        "#### Grouping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq84-TbJ-j5S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "c0a5f50e-3fd1-42ea-c7b0-418085175d12"
      },
      "source": [
        "trainDF.groupBy(\"Age\", \"Gender\").count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+-----+\n",
            "|  Age|Gender|count|\n",
            "+-----+------+-----+\n",
            "|51-55|     F| 4021|\n",
            "|18-25|     M|30307|\n",
            "| 0-17|     F| 1976|\n",
            "|46-50|     M|13017|\n",
            "|18-25|     F| 9926|\n",
            "|  55+|     M| 6599|\n",
            "|  55+|     F| 2030|\n",
            "|36-45|     M|33112|\n",
            "|26-35|     F|20151|\n",
            "| 0-17|     M| 4014|\n",
            "|36-45|     F|10849|\n",
            "|51-55|     M|11410|\n",
            "|26-35|     M|67844|\n",
            "|46-50|     F| 5258|\n",
            "+-----+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1rNtNTr-j5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "e12cca17-d898-4733-e8c0-424d9893fcc8"
      },
      "source": [
        "trainDF.select(\"Age\",\"Gender\",\"Purchase\").groupBy(\"Age\",\"Gender\").sum(\"Purchase\").alias(\"Age Group Purchase\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+-------------+\n",
            "|  Age|Gender|sum(Purchase)|\n",
            "+-----+------+-------------+\n",
            "|51-55|     F|     36202846|\n",
            "|18-25|     M|    285067216|\n",
            "| 0-17|     F|     16602902|\n",
            "|46-50|     M|    121957420|\n",
            "|18-25|     F|     82547523|\n",
            "|  55+|     M|     62468497|\n",
            "|  55+|     F|     18103298|\n",
            "|36-45|     M|    313934889|\n",
            "|26-35|     F|    176288527|\n",
            "| 0-17|     M|     36869675|\n",
            "|36-45|     F|     96853551|\n",
            "|51-55|     M|    110785049|\n",
            "|26-35|     M|    636249540|\n",
            "|46-50|     F|     45832195|\n",
            "+-----+------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlEXtXrj-j5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "4aeec290-2fa3-46d6-fd2b-0af516b73b2c"
      },
      "source": [
        "trainDF.select(\"Age\",\"Gender\",\"Purchase\").groupBy(\"Age\",\"Gender\").agg(sum(\"Purchase\").alias(\"Age Group Purchase\"), avg(\"Purchase\").alias(\"Mean Age Group Purchase\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+------------------+-----------------------+\n",
            "|  Age|Gender|Age Group Purchase|Mean Age Group Purchase|\n",
            "+-----+------+------------------+-----------------------+\n",
            "|51-55|     F|          36202846|       9003.44342203432|\n",
            "|18-25|     M|         285067216|      9405.985943841357|\n",
            "| 0-17|     F|          16602902|      8402.278340080971|\n",
            "|46-50|     M|         121957420|      9369.088115541215|\n",
            "|18-25|     F|          82547523|       8316.29286721741|\n",
            "|  55+|     M|          62468497|      9466.358084558266|\n",
            "|  55+|     F|          18103298|       8917.88078817734|\n",
            "|36-45|     M|         313934889|      9481.000513409035|\n",
            "|26-35|     F|         176288527|      8748.376110366731|\n",
            "| 0-17|     M|          36869675|      9185.270303936224|\n",
            "|36-45|     F|          96853551|      8927.417365655821|\n",
            "|51-55|     M|         110785049|       9709.46967572305|\n",
            "|26-35|     M|         636249540|      9378.125405341667|\n",
            "|46-50|     F|          45832195|      8716.659376188665|\n",
            "+-----+------+------------------+-----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJnY7rYn-j5w"
      },
      "source": [
        "#### Grouping with Expressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cql7tK_P-j50",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0d20dd4a-80e4-4b93-ae3d-058a8ebfe431"
      },
      "source": [
        "trainDF.groupBy(\"Age\").agg(\n",
        "  count(\"Purchase\").alias(\"quan\"),\n",
        "  expr(\"count(Purchase)\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+---------------+\n",
            "|  Age| quan|count(Purchase)|\n",
            "+-----+-----+---------------+\n",
            "|18-25|40233|          40233|\n",
            "|26-35|87995|          87995|\n",
            "| 0-17| 5990|           5990|\n",
            "|46-50|18275|          18275|\n",
            "|51-55|15431|          15431|\n",
            "|36-45|43961|          43961|\n",
            "|  55+| 8629|           8629|\n",
            "+-----+-----+---------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juwzudMM-j5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "af87cbe9-4ff7-4785-c611-9f36b910b8c1"
      },
      "source": [
        "trainDF.groupBy(\"Age\").agg(expr(\"avg(Purchase)\"),expr(\"stddev_pop(Purchase)\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----------------+--------------------+\n",
            "|  Age|    avg(Purchase)|stddev_pop(Purchase)|\n",
            "+-----+-----------------+--------------------+\n",
            "|18-25|9137.144607660379|   5030.064681284094|\n",
            "|26-35|9233.911779078357|   5000.033602828318|\n",
            "| 0-17|8926.974457429049|   5085.392112027391|\n",
            "|46-50|9181.374281805745|  4927.6155514087095|\n",
            "|51-55|9525.493811159355|   5080.055180428372|\n",
            "|36-45|9344.383430768181|   5028.548097475931|\n",
            "|  55+|9337.327036736586|   5026.353904353003|\n",
            "+-----+-----------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-BCIC_O-j6Q",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "85a8bd03-f829-4d15-c4fc-6edc78544a7d"
      },
      "source": [
        "## To find the mean of each age group in train dataset - Average purchases in each age group\n",
        "trainDF.groupby('Age').agg({'Purchase': 'mean'}).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----------------+\n",
            "|  Age|    avg(Purchase)|\n",
            "+-----+-----------------+\n",
            "|18-25|9137.144607660379|\n",
            "|26-35|9233.911779078357|\n",
            "| 0-17|8926.974457429049|\n",
            "|46-50|9181.374281805745|\n",
            "|51-55|9525.493811159355|\n",
            "|36-45|9344.383430768181|\n",
            "|  55+|9337.327036736586|\n",
            "+-----+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGtajFNz-j6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "952b272c-a895-4d2d-9971-6d67272ef369"
      },
      "source": [
        "trainDF.groupby('Age').agg({'Purchase': 'sum'}).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------------+\n",
            "|  Age|sum(Purchase)|\n",
            "+-----+-------------+\n",
            "|18-25|    367614739|\n",
            "|26-35|    812538067|\n",
            "| 0-17|     53472577|\n",
            "|46-50|    167789615|\n",
            "|51-55|    146987895|\n",
            "|36-45|    410788440|\n",
            "|  55+|     80571795|\n",
            "+-----+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4m1NCTZ-j6f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "7e21394d-8982-4733-df3b-e26e90eb95cd"
      },
      "source": [
        "## Apply sum, min, max, count with groupby to get different summary insight for each group. \n",
        "exprs = {x: \"sum\" for x in trainDF.columns}\n",
        "trainDF.groupBy(\"Age\").agg(exprs).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------------------+-----------------------+-------------------+-------------+------------+---------------+-------------------------------+-----------------------+--------+-----------+-----------------------+---------------+\n",
            "|  Age|sum(City_Category)|sum(Product_Category_3)|sum(Marital_Status)|sum(Purchase)|sum(User_ID)|sum(Occupation)|sum(Stay_In_Current_City_Years)|sum(Product_Category_1)|sum(Age)|sum(Gender)|sum(Product_Category_2)|sum(Product_ID)|\n",
            "+-----+------------------+-----------------------+-------------------+-------------+------------+---------------+-------------------------------+-----------------------+--------+-----------+-----------------------+---------------+\n",
            "|18-25|              null|                 156493|               8469|    367614739| 40345895081|         271247|                        47104.0|                 204957|    null|       null|                 264391|           null|\n",
            "|26-35|              null|                 338487|              34678|    812538067| 88269208395|         695426|                       110599.0|                 468818|    null|       null|                 591971|           null|\n",
            "| 0-17|              null|                  23290|                  0|     53472577|  6006326887|          52562|                         8070.0|                  30216|    null|       null|                  37926|           null|\n",
            "|46-50|              null|                  68888|              13276|    167789615| 18333402511|         153891|                        20655.0|                 105222|    null|       null|                 126226|           null|\n",
            "|51-55|              null|                  59580|              11134|    146987895| 15477078947|         135885|                        17613.0|                  88926|    null|       null|                 107195|           null|\n",
            "+-----+------------------+-----------------------+-------------------+-------------+------------+---------------+-------------------------------+-----------------------+--------+-----------+-----------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqdS_JM9-j6k"
      },
      "source": [
        "### 16. User-Defined Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnVv-y64-j6m"
      },
      "source": [
        "##### a. simple UDF function for finding the cube of a number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwKQygea-j6n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d708999-3158-4ee9-98b1-12af908919a2"
      },
      "source": [
        "udfExampleDF = spark.range(5).toDF(\"num\")\n",
        "\n",
        "def power3(double_value):\n",
        "    return double_value ** 3\n",
        "\n",
        "power3(2.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXRJT_bG-j6x"
      },
      "source": [
        "Once the function is created, we need to register them with Spark so that we can used\n",
        "them on all of our worker machines. Spark will serialize the function on the driver, and transfer it over the network to all executor processes. This happens regardless of language.\n",
        "\n",
        "<br>Once we go to use the function, there are essentially two different things that occur. If the function is written in Scala or Java then we can use that function within the JVM. This means there will be little performance penalty aside from the fact that we can’t take advantage of code generation capabilities that Spark has for built-in functions.\n",
        "\n",
        "<br>If the function is written in Python, something quite different happens. \n",
        "Spark will start up a python process on the worker, serialize all of the data to a format that python can understand (remember it was in the JVM before), execute the function row by row on that data in the python process, before finally returning the results of the row operations to the JVM and Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCEcNrvX-j60"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "power3udf = udf(power3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGnxpzhH-j7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "68e3b7e4-ce62-4ef7-8a97-0d8ee2fd421a"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "udfExampleDF.select(power3udf(col(\"num\"))).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|power3(num)|\n",
            "+-----------+\n",
            "|          0|\n",
            "|          1|\n",
            "|          8|\n",
            "|         27|\n",
            "|         64|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdXByH_M-j7P"
      },
      "source": [
        "##### b. Binning of Purchase column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBklXJQN-j7U"
      },
      "source": [
        "def binning_purchase(purchase):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        Accepts Purchase amount and returns the correspondin bin\n",
        "    return:\n",
        "        bin number (Bin01,02,....) type=String\n",
        "    0       - 500       -> Bin01\n",
        "    501     - 1000      -> Bin02\n",
        "    1001    - 2000      -> Bin03\n",
        "    2001    - 4000      -> Bin04\n",
        "    4001    - 6000      -> Bin05\n",
        "    6001    - 8000      -> Bin06\n",
        "    8001    - 10000     -> Bin07\n",
        "    10001   - 20000     -> Bin08\n",
        "    20001   - 30000     -> Bin09\n",
        "    \"\"\"\n",
        "    if float(purchase) > 0:\n",
        "        purchase = float(purchase)\n",
        "    else:\n",
        "        purchase = float(0)\n",
        "    \n",
        "    if purchase <= 500: return str(\"Bin01\")\n",
        "    elif (purchase > 500 and purchase <= 1000): return str(\"Bin02\")\n",
        "    elif (purchase > 1000 and purchase <= 2000): return str(\"Bin03\")\n",
        "    elif (purchase > 2000 and purchase <= 4000): return str(\"Bin04\")\n",
        "    elif (purchase > 4000 and purchase <= 6000): return str(\"Bin05\")\n",
        "    elif (purchase > 6000 and purchase <= 8000): return str(\"Bin06\")\n",
        "    elif (purchase > 8000 and purchase <= 10000): return str(\"Bin07\")\n",
        "    elif (purchase > 10000 and purchase <= 20000): return str(\"Bin08\")\n",
        "    else:\n",
        "        return str(\"Bin09\")\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z9JKOjr-j7Z"
      },
      "source": [
        "bin_purchase_udf = udf(binning_purchase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smr7MFid-j7h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ea843705-7e82-4675-dcc0-3cc890ca88bb"
      },
      "source": [
        "trainDF.withColumn('Binned_Purchase',bin_purchase_udf('Purchase')).select(\"Purchase\",\"Binned_Purchase\").show(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------+\n",
            "|Purchase|Binned_Purchase|\n",
            "+--------+---------------+\n",
            "|   16622|          Bin08|\n",
            "|    1057|          Bin03|\n",
            "|    8094|          Bin07|\n",
            "|   10003|          Bin08|\n",
            "+--------+---------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO34X5_8-j7m"
      },
      "source": [
        "## 17. Joins\n",
        "\n",
        "#### Dataset\n",
        "* The data is obtained from Surfeous,a recommender system prototype that uses social annotations (e.g., tags) and contextual models to find restaurants that best suit the user preferences.It is a publicly available dataset in UCI.It has threee tables restaurants,consumers and user rating.The tables we choose are from them which are fitered for our scenario\n",
        "\n",
        "\n",
        "#### Data dictionary :\n",
        "* __RestGenInfo.csv__ contains :\n",
        "    * placeID - Uniqued Id of restaurants\n",
        "    * latitude - Location detail \n",
        "    * longitude - Location detail\n",
        "    * name - Name of the restaurant\n",
        "    * state - Name of the state \n",
        "    * alcohol - Constraints on having alcoholic beverages\n",
        "    * smoking_area - Information for smokers\n",
        "    * price - Pricing type of restaurant\n",
        "    * franchise - Does the restaurant have frachise\n",
        "    * area - open or close type of restaurant\n",
        "\n",
        "* __Cuisine.csv__ contains :\n",
        "    * placeID - Uniqued Id of restaurants\n",
        "    * Rcuisine - Different styles of food\n",
        "\n",
        "    \n",
        "* __PaymentMode.csv__ contains :\n",
        "    * placeID - Uniqued Id of restaurants\n",
        "    * Rpayment - Different modes of payment\n",
        "\n",
        "    \n",
        "* __parking.csv__ contains :\n",
        "     * placeID - Uniqued Id of restaurants\n",
        "     * parking_lot - Different types of parking available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GnMuOL9-j7p"
      },
      "source": [
        "#### Read the data as a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcuy68kj-j7s"
      },
      "source": [
        "restoGen = spark.read.csv('drive/My Drive/SparkSQL/data/RestaurantsData/RestGenInfo.csv', header=True, inferSchema=True,nullValue='?')\n",
        "cuisine = spark.read.csv('drive/My Drive/SparkSQL/data/RestaurantsData/Cuisine.csv', header=True, inferSchema=True)\n",
        "paymentMode = spark.read.csv('drive/My Drive/SparkSQL/data/RestaurantsData/PaymentMode.csv', header=True, inferSchema=True)\n",
        "parking = spark.read.csv('drive/My Drive/SparkSQL/data/RestaurantsData/parking.csv', header=True, inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Geldi8NC-j7w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "2133a5f9-9350-4da9-e938-882064d932e5"
      },
      "source": [
        "restoGen.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------+------------+--------------------+----------+-----------------+-------------+------+---------+------+\n",
            "|placeID|  latitude|   longitude|                name|     state|          alcohol| smoking_area| price|franchise|  area|\n",
            "+-------+----------+------------+--------------------+----------+-----------------+-------------+------+---------+------+\n",
            "| 132560|23.7523041| -99.1669133|  puesto de gorditas|Tamaulipas|No_Alcohol_Served|    permitted|   low|        f|  open|\n",
            "| 132561| 23.726819| -99.1265059|          cafe ambar|      null|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132564|23.7309245| -99.1451848|             churchs|      null|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132572|22.1416471|-100.9927118|        Cafe Chaires|       SLP|No_Alcohol_Served|not permitted|   low|        f|closed|\n",
            "| 132583|18.9222904|  -99.234332|    McDonalds Centro|   Morelos|No_Alcohol_Served|not permitted|   low|        t|closed|\n",
            "| 132584|23.7523648| -99.1652879|  Gorditas Dona Tota|      null|No_Alcohol_Served|not permitted|medium|        t|closed|\n",
            "| 132594|23.7521677|  -99.165709|tacos de barbacoa...|      null|No_Alcohol_Served|not permitted|   low|        f|  open|\n",
            "| 132608|23.7588052| -99.1651297|Hamburguesas La p...|Tamaulipas|No_Alcohol_Served|    permitted|   low|        t|  open|\n",
            "| 132609|23.7602683| -99.1658646|Pollo_Frito_Bueno...|Tamaulipas|No_Alcohol_Served|not permitted|   low|        t|closed|\n",
            "| 132613|23.7529035|  -99.165076|       carnitas_mata|Tamaulipas|No_Alcohol_Served|    permitted|medium|        t|closed|\n",
            "| 132626|23.7375834| -99.1351318|la perica hamburg...|Tamaulipas|No_Alcohol_Served|         none|medium|        t|closed|\n",
            "| 132630|23.7529305| -99.1644725|          palomo tec|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132654|23.7355234| -99.1295877|Carnitas Mata  Ca...|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132660|23.7529428| -99.1646791|carnitas mata cal...|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132663|23.7525107| -99.1669536|           tacos abi|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132665|23.7367977| -99.1342413|  TACOS CORRECAMINOS|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132667|23.7526973| -99.1633594|little pizza Emil...|Tamaulipas|No_Alcohol_Served|         none|   low|        t|closed|\n",
            "| 132668| 23.738212| -99.1519547|      TACOS EL GUERO|Tamaulipas|No_Alcohol_Served|         none|   low|        f|closed|\n",
            "| 132706|23.7292162| -99.1323571|  Gorditas Dona Tota|Tamaulipas|No_Alcohol_Served|not permitted|medium|        t|closed|\n",
            "| 132715|23.7324226| -99.1586602|tacos de la estacion|      null|No_Alcohol_Served|         none|   low|        f|  open|\n",
            "+-------+----------+------------+--------------------+----------+-----------------+-------------+------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT4e6wAY-j74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87a0a728-d6a4-4e75-ba68-72a3ed721aee"
      },
      "source": [
        "restoGen.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5Xj3j5S-j8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "772eee6f-4b1c-4918-c8a0-11aa56278589"
      },
      "source": [
        "restoGen.select('PlaceID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRpWj1rw-j8V"
      },
      "source": [
        "#### Check for any null values in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2eX0X0l-j8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f61f48ee-6f11-45cf-8c2e-be71bdb6f638"
      },
      "source": [
        "restoGen.select([count(when(isnan(c)| col(c).isNull(), 1)).alias(c) for c in restoGen.columns]).show()\n",
        "cuisine.select([count(when(isnan(c)| col(c).isNull(), 1)).alias(c) for c in cuisine.columns]).show()\n",
        "paymentMode.select([count(when(isnan(c)| col(c).isNull(), 1)).alias(c) for c in paymentMode.columns]).show()\n",
        "parking.select([count(when(isnan(c)| col(c).isNull(), 1)).alias(c) for c in parking.columns]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------+---------+----+-----+-------+------------+-----+---------+----+\n",
            "|placeID|latitude|longitude|name|state|alcohol|smoking_area|price|franchise|area|\n",
            "+-------+--------+---------+----+-----+-------+------------+-----+---------+----+\n",
            "|      0|       0|        0|   0|   18|      0|           0|    0|        0|   0|\n",
            "+-------+--------+---------+----+-----+-------+------------+-----+---------+----+\n",
            "\n",
            "+-------+--------+\n",
            "|placeID|Rcuisine|\n",
            "+-------+--------+\n",
            "|      0|       0|\n",
            "+-------+--------+\n",
            "\n",
            "+-------+--------+\n",
            "|placeID|Rpayment|\n",
            "+-------+--------+\n",
            "|      0|       0|\n",
            "+-------+--------+\n",
            "\n",
            "+-------+-----------+\n",
            "|placeID|parking_lot|\n",
            "+-------+-----------+\n",
            "|      0|          0|\n",
            "+-------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awTweRHO-j8m"
      },
      "source": [
        "restoGen = restoGen.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EACIDtv--j9C"
      },
      "source": [
        "restoGen.select('placeID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRDLeAZC-j9H"
      },
      "source": [
        "cuisine.select('placeID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLWHRAHk-j9L"
      },
      "source": [
        "paymentMode.select('placeID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wEAwcJ1-j9S"
      },
      "source": [
        "parking.select('placeID').distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK8HLuax-j9b"
      },
      "source": [
        "cuisine.select('Rcuisine').distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAkgy85N-j9n"
      },
      "source": [
        "restoGen.createOrReplaceTempView('restoGenTable')\n",
        "cuisine.createOrReplaceTempView('cuisineTable')\n",
        "paymentMode.createOrReplaceTempView('paymentModeTable')\n",
        "parking.createOrReplaceTempView('parkingTable')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjmZF_OY-j9u"
      },
      "source": [
        " ## The  count of restaurants(as numberOfHotels) for each payment modes and area. Also order them based on numberOfHotels in descending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al5SVWqH-j9x"
      },
      "source": [
        "spark.sql('''select  count(*) as numberOfHotels, Rpayment, area from\n",
        "restoGenTable a join paymentModeTable b \n",
        "where a.placeID = b.placeID group by Rpayment, area \n",
        "order by numberOfHotels desc''').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ0U5mkJ-j94"
      },
      "source": [
        "#### Inner Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "605Lr6fX-j95"
      },
      "source": [
        "inner_join = restoGen.join(paymentMode, restoGen.placeID == paymentMode.placeID,how='inner') \n",
        "inner_join.show(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRkVke1S-j-K"
      },
      "source": [
        "count_of_hotels = inner_join.select('Rpayment','area').groupby('area','Rpayment').count()\n",
        "\n",
        "count_of_hotels = count_of_hotels.withColumnRenamed('count','NumberofHotels')\n",
        "count_of_hotels.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a75aiWy--j-T",
        "scrolled": true
      },
      "source": [
        "count_of_hotels.orderBy(count_of_hotels.NumberofHotels.desc()).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpdB8ulI-j-d"
      },
      "source": [
        "##  Count the number of Cuisines that are used by the Restaurants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qASg3a7w-j-f"
      },
      "source": [
        "print(\"The number of Disintct Cuisines Available from all the restaurants = \",cuisine.select('Rcuisine').distinct().count())\n",
        "left_join = restoGen.join(cuisine, on=restoGen.placeID==cuisine.placeID, how = 'left').drop(cuisine.placeID)\n",
        "print(\"The number of cusines used in the selected Restaurants: \")\n",
        "left_join.select(countDistinct('Rcuisine').alias(\" Distinct Cusines  used in Restaurants\")).show()\n",
        "print(\"The Cusinies available are \")\n",
        "left_join.select('Rcuisine').distinct().alias(\"Cusines  used in Restaurants\").show(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdgM5sfQ-j-o"
      },
      "source": [
        "## Count the distinct restaurant names which has valet parking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziLc5rg6-j-p"
      },
      "source": [
        "spark.sql('''select distinct name ,parking_lot from restoGenTable a join parkingTable b where a.placeID = b.placeID and \n",
        "          b.parking_lot = 'valet parking' ''').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzQxk1u4-j-x"
      },
      "source": [
        "#### Right Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMAFi8C7-j-y"
      },
      "source": [
        "right_join = restoGen.join(other=parking,on=parking.placeID==restoGen.placeID,how='right')\n",
        "names_of_restaurants = right_join.select('name','parking_lot').filter(parking.parking_lot=='valet parking')\n",
        "names_of_restaurants.distinct().filter(names_of_restaurants.name!='null').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUtv3m9n-j-7"
      },
      "source": [
        "## Identify the placeID where the paymentMode for parking  is not available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSlQswA7-j-8"
      },
      "source": [
        "#### Full outer Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdGPnOas-j-9"
      },
      "source": [
        "spark.sql(\"\"\"SELECT parkingTable.placeID,parkingTable.parking_lot,paymentModeTable.Rpayment\n",
        "FROM parkingTable\n",
        "FULL OUTER JOIN paymentModeTable ON parkingTable.placeID=paymentModeTable.placeID WHERE paymentModeTable.Rpayment is NULL\"\"\").show(1000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Ag_0ai-j_F"
      },
      "source": [
        "## The restaurant names and their corresponding restaurant cuisine styles, price, location details(latitude, longitude) and smoking_area informations only for those which are located in Morelos state and have closed roofing, also order based on price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNV2pUKQ-j_H"
      },
      "source": [
        "spark.sql('''select distinct name, Rcuisine, price, latitude, longitude, smoking_area from \n",
        "restoGenTable a join cuisineTable b \n",
        "where a.placeID = b.placeID and a.state = 'Morelos' and a.area = 'closed' \n",
        "order by price''').show(truncate = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7jgFNs0-j_M"
      },
      "source": [
        "#### Natural Joins\n",
        "Natural joins make implicit guesses at the columns on which you would like to join. \n",
        "It finds matching columns and returns the results. \n",
        "Left, right, and outer natural joins are all supported.\n",
        "\n",
        "WARNING:\n",
        "Implicit is always dangerous! \n",
        "The following query will give us incorrect results because \n",
        "the two DataFrames/tables share a column name (id), but it means different things in the datasets. \n",
        "You should always use this join with caution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJaxYX3P-j_N",
        "scrolled": true
      },
      "source": [
        "#spark.sql(\"\"\"SELECT * FROM TableA NATURAL JOIN TableB\"\"\").show()\n",
        "\n",
        "spark.sql('''select  * from restoGenTable a NATURAL JOIN paymentModeTable b ''').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0UPTuxg-j_S"
      },
      "source": [
        "#### Cross (Cartesian) Joins\n",
        "Cross-joins in simplest terms are inner joins that do not specify a predicate. \n",
        "Cross joins will join every single row in the left DataFrame to ever single row in the right DataFrame. \n",
        "This will cause an absolute explosion in the number of rows contained in the resulting DataFrame. \n",
        "If you have 1,000 rows in each DataFrame, the cross-join of these will result in 1,000,000 (1,000 x 1,000) rows. \n",
        "For this reason, you must very explicitly state that you want a cross-join by using the cross join keyword:"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "u4tAmGAs-j_f",
        "scrolled": true
      },
      "source": [
        "tableA.crossJoin(tableB).show()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "bUD7qiEI-j_g",
        "scrolled": true
      },
      "source": [
        "spark.sql(\"\"\"SELECT * FROM TableA CROSS JOIN TableB\"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTsCTnHd-j_i"
      },
      "source": [
        "#### Random Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJip1KX1-j_j"
      },
      "source": [
        "## To create a sample DataFrame from the base DataFrame\n",
        "## Use sample operation to take sample of a DataFrame. \n",
        "## The sample method on DataFrame will return a DataFrame containing the sample of base DataFrame. \n",
        "## The sample method takes 3 parameters.\n",
        "## withReplacement = True or False to select a observation with or without replacement.\n",
        "## fraction = x, where x = .5 shows that we want to have 50% data in sample DataFrame.\n",
        "## seed to reproduce the result\n",
        "sampleDF1 = trainDF.sample(False, 0.2, 1234)\n",
        "sampleDF2 = trainDF.sample(False, 0.2, 4321)\n",
        "print(sampleDF1.count(), sampleDF2.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzqvaZTB-j_q"
      },
      "source": [
        "### Miscellaneous"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPVh4YUx-j_r"
      },
      "source": [
        "#### Unions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-oQLwix-j_t",
        "outputId": "be4563c5-79a3-4b3f-d0cb-214c890aeb05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "df1 = spark.createDataFrame([[1, 'Alex', 25],[3, 'Carol', 53],[5, 'Emily', 25],[7, 'Gabriel', 32],[9, 'Ilma', 35],[11, 'Kim', 45]], ['id', 'name', 'age'])\n",
        "df2 = spark.createDataFrame([[2, 'Ben', 66],[4, 'Daniel', 28],[6, 'Frank', 64],[8, 'Harley', 29],[10, 'Jack', 35],[12, 'Litmya', 45]], ['id', 'name', 'age'])\n",
        "print(\"Before\")\n",
        "print(\"DataFrame-1\")\n",
        "print(df1.show())\n",
        "print(\"DataFrame-2\")\n",
        "print(df2.show())\n",
        "print(\"After\")\n",
        "df1 = df1.union(df2)\n",
        "print(\"DataFrame-1\")\n",
        "print(df1.show())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before\n",
            "DataFrame-1\n",
            "+---+-------+---+\n",
            "| id|   name|age|\n",
            "+---+-------+---+\n",
            "|  1|   Alex| 25|\n",
            "|  3|  Carol| 53|\n",
            "|  5|  Emily| 25|\n",
            "|  7|Gabriel| 32|\n",
            "|  9|   Ilma| 35|\n",
            "| 11|    Kim| 45|\n",
            "+---+-------+---+\n",
            "\n",
            "None\n",
            "DataFrame-2\n",
            "+---+------+---+\n",
            "| id|  name|age|\n",
            "+---+------+---+\n",
            "|  2|   Ben| 66|\n",
            "|  4|Daniel| 28|\n",
            "|  6| Frank| 64|\n",
            "|  8|Harley| 29|\n",
            "| 10|  Jack| 35|\n",
            "| 12|Litmya| 45|\n",
            "+---+------+---+\n",
            "\n",
            "None\n",
            "After\n",
            "DataFrame-1\n",
            "+---+-------+---+\n",
            "| id|   name|age|\n",
            "+---+-------+---+\n",
            "|  1|   Alex| 25|\n",
            "|  3|  Carol| 53|\n",
            "|  5|  Emily| 25|\n",
            "|  7|Gabriel| 32|\n",
            "|  9|   Ilma| 35|\n",
            "| 11|    Kim| 45|\n",
            "|  2|    Ben| 66|\n",
            "|  4| Daniel| 28|\n",
            "|  6|  Frank| 64|\n",
            "|  8| Harley| 29|\n",
            "| 10|   Jack| 35|\n",
            "| 12| Litmya| 45|\n",
            "+---+-------+---+\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW1VnmLs-j_9"
      },
      "source": [
        "#### Unions and condtional append"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4LcxthZ-kAF"
      },
      "source": [
        "df1.union(df2).where(\"age < 60\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b37tnE11-kAi"
      },
      "source": [
        "#### String Manipulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24EvVNv5-kAl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e9cfa491-e166-4bf1-9134-042699e83c9e"
      },
      "source": [
        "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim\n",
        "\n",
        "trainDF.select(\n",
        "ltrim(lit(\" HELLO \")).alias(\"ltrim\"),\n",
        "rtrim(lit(\" HELLO \")).alias(\"rtrim\"),\n",
        "trim(lit(\" HELLO \")).alias(\"trim\"),\n",
        "lpad(lit(\"HELLO\"), 7, \" \").alias(\"lp\"),\n",
        "rpad(lit(\"HELLO\"), 7, \" \").alias(\"rp\"))\\\n",
        ".show(2,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+------+-----+-------+-------+\n",
            "|ltrim |rtrim |trim |lp     |rp     |\n",
            "+------+------+-----+-------+-------+\n",
            "|HELLO | HELLO|HELLO|  HELLO|HELLO  |\n",
            "|HELLO | HELLO|HELLO|  HELLO|HELLO  |\n",
            "+------+------+-----+-------+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMIO97nf-kAv"
      },
      "source": [
        "spark.sql(\"\"\"SELECT\n",
        "ltrim(' HELLLOOOO ') AS ltrim,\n",
        "rtrim(' HELLLOOOO ') AS rtrim,\n",
        "trim(' HELLLOOOO ') AS trim,\n",
        "lpad('HELLOOOO ', 3, ' ') AS lp,\n",
        "rpad('HELLOOOO ', 10, ' ') AS rp\n",
        "FROM\n",
        "trainDFTable\"\"\").show(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYI5XPtd-kA6"
      },
      "source": [
        "#### Working with Date and Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn9fY5Fe-kA-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c489bc2c-6d89-412f-9348-51d99b1862be"
      },
      "source": [
        "from pyspark.sql.functions import current_date, current_timestamp\n",
        "dateDF = spark.range(10)\\\n",
        ".withColumn(\"today\", current_date())\\\n",
        ".withColumn(\"now\", current_timestamp())\n",
        "dateDF.show(truncate = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----------+-----------------------+\n",
            "|id |today     |now                    |\n",
            "+---+----------+-----------------------+\n",
            "|0  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "|1  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "|2  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "|3  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "|4  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "|5  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "|6  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "|7  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "|8  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "|9  |2020-02-16|2020-02-16 01:41:51.534|\n",
            "+---+----------+-----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1sqSq8o-kBR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6ba79d39-e04e-4bcd-9317-9526226309a8"
      },
      "source": [
        "dateDF.createOrReplaceTempView(\"dateDFTable\")\n",
        "dateDF.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: long (nullable = false)\n",
            " |-- today: date (nullable = false)\n",
            " |-- now: timestamp (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zAbT2Oo-kBn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7910342d-69b7-46c3-a79d-e800c6809f5c"
      },
      "source": [
        "from pyspark.sql.functions import date_add, date_sub\n",
        "dateDF.select(date_sub(col(\"today\"), 10),date_add(col(\"today\"), 10)).show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-------------------+\n",
            "|date_sub(today, 10)|date_add(today, 10)|\n",
            "+-------------------+-------------------+\n",
            "|         2020-02-06|         2020-02-26|\n",
            "+-------------------+-------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojQ1qjpD-kB0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5d644a5c-61a4-4c75-f084-8cb4b21ce73f"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "date_sub(today, 10),\n",
        "date_add(today, 10)\n",
        "FROM\n",
        "dateDFTable\n",
        "\"\"\").show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-------------------+\n",
            "|date_sub(today, 10)|date_add(today, 10)|\n",
            "+-------------------+-------------------+\n",
            "|         2020-02-06|         2020-02-26|\n",
            "+-------------------+-------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FescWtwv-kCA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "19923dbe-4241-41dc-c63d-727b01412f9a"
      },
      "source": [
        "from pyspark.sql.functions import datediff, months_between, to_date\n",
        "dateDF\\\n",
        ".withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\\\n",
        ".select(datediff(col(\"week_ago\"), col(\"today\")).alias('datediff_today_weekago'))\\\n",
        ".show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+\n",
            "|datediff_today_weekago|\n",
            "+----------------------+\n",
            "|                    -7|\n",
            "+----------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2knMtDUZ-kCK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "239b096e-b9f8-4928-9f38-caac37e61551"
      },
      "source": [
        "dateDF\\\n",
        ".select(\n",
        "to_date(lit(\"2017-01-01\")).alias(\"start\"),\n",
        "to_date(lit(\"2018-02-18\")).alias(\"end\"))\\\n",
        ".select(months_between(col(\"end\"), col(\"start\")))\\\n",
        ".show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------+\n",
            "|months_between(end, start)|\n",
            "+--------------------------+\n",
            "|                13.5483871|\n",
            "+--------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NACbhT5-kCT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d378ee92-a836-4d09-921e-9a9e580bde5e"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "to_date('2016-01-01') AS date,\n",
        "months_between('2017-01-01', '2016-01-01') AS months_between,\n",
        "datediff('2017-01-01', '2016-01-01') AS datediff_days\n",
        "FROM\n",
        "dateDFTable\n",
        "\"\"\").show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------+-------------+\n",
            "|      date|months_between|datediff_days|\n",
            "+----------+--------------+-------------+\n",
            "|2016-01-01|          12.0|          366|\n",
            "|2016-01-01|          12.0|          366|\n",
            "+----------+--------------+-------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJLASD4w-kCl"
      },
      "source": [
        "__WARNING__\n",
        "<br>Spark will not throw an error if it cannot parse the date, it’ll just return null. This can be a bit tricky in larger pipelines because you may be expecting your data in one format and getting it in another. To illustrate, let’s take a look at the date format that has switched from year-month-day to year-day-month. Spark will fail to parse this date and silently return null instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZeluEUl-kCp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8a1ec2eb-aaac-456e-b524-3fdc2b6cf9ba"
      },
      "source": [
        "### 2016-20-12 - year-day-month\n",
        "### 2017-12-11 - year-month-day\n",
        "dateDF.select(to_date(lit(\"2016-20-12\")),to_date(lit(\"2017-12-11\"))).show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------+---------------------+\n",
            "|to_date('2016-20-12')|to_date('2017-12-11')|\n",
            "+---------------------+---------------------+\n",
            "|                 null|           2017-12-11|\n",
            "+---------------------+---------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVcpA9uU8pl3"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}